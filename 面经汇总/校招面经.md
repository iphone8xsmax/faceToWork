[toc]



### 1.Go相关

#### 1.go map底层原理及实现

总体来说golang的map是hashmap，是使用**数组+链表**的形式实现的，使用**拉链法消除hash冲突**。

golang的map由两种重要的结构，**hmap和bmap**，hmap中包含一个指向bmap数组的指针，key经过hash函数之后得到一个数，这个数低位用于选择bmap(当作bmap数组指针的下标)，高位用于放在bmap的[8]uint8数组中，用于快速试错。然后一个bmap可以指向下一个bmap(拉链)。

Golang中`map`的底层实现是一个散列表，因此实现`map`的过程实际上就是实现散表的过程。在这个散列表中，主要出现的结构体有两个，一个叫**`hmap`**(`a header for a go map`)，一个叫**`bmap`**(`a bucket for a Go map`，通常叫其`bucket`)。这两种结构的样子分别如下所示：

##### **Hmap:**

<img src="校招面经.assets/09d0c94fc2946bba795ecc2ae0c97ac2.png" alt="img" style="zoom:50%;" />

##### **Bucket:**

Golang的map中用于存储的结构是bucket数组。而bucket(即`bmap`)的结构是怎样的呢？

<img src="校招面经.assets/1199549-20190622233814630-764863225.png" alt="img" style="zoom:50%;" />

使用的`map`中的key和value就存储在这里。**“高位哈希值”数组记录的是当前bucket中key相关的“索引”**，稍后会详细叙述。还有一个字段是一个**指向扩容后的bucket的指针，使得bucket会形成一个链表结构**。

##### **hmap和bmap的关系：**

<img src="校招面经.assets/1199549-20190622232825554-644793812.png" alt="img" style="zoom:50%;" />

而bucket又是一个链表，所以，整体的结构应该是这样的：

<img src="校招面经.assets/1199549-20190622233114658-1984741865.png" alt="img" style="zoom:50%;" />

哈希表的特点是会有一个哈希函数，对你传来的key进行哈希运算，得到唯一的值，一般情况下都是一个数值。Golang的`map`中也有这么一个哈希函数，也会算出唯一的值，对于这个值的使用，Golang也是很有意思。

Golang把求得的值按照用途一分为二：**高位和低位**。

**低位用于寻找当前key属于`hmap`中的哪个bucket，而高位用于寻找bucket中的哪个key**。上文中提到：bucket中有个属性字段是“高位哈希值”数组，这里存的就是蓝色的高位值，用来声明当前bucket中有哪些“key”，便于搜索查找。 需要特别指出的一点是：我们`map`中的**key/value值都是存到同一个数组中的**。数组中的顺序是这样的:

<img src="校招面经.assets/a662bfc57e0b63211f1f2783129969c6.png" alt="这里写图片描述" style="zoom:50%;" />

这样做的好处是：在key和value的**长度不同**的时候，可**以消除padding(内存对齐)带来的空间浪费**。

现在，我们可以得到Go语言`map`的整个的结构图了：(hash结果的**低位用于选择把KV放在bmap数组中的哪一个**bmap中，**高位用于key的快速预览**，用于快速试错)

<img src="校招面经.assets/7d806b2a30f30d85e3ee65fb25929263.png" alt="这里写图片描述" style="zoom:50%;" />

##### **map的扩容**

当以上的哈希表增长的时候，Go语言会将bucket数组的数量扩充一倍，产生一个新的bucket数组，并将旧数组的数据迁移至新数组。

**判断扩充的条件**，就是哈希表中的**加载因子**(即loadFactor)。

加载因子是一个阈值，一般表示为：**散列包含的元素数除以位置总数**。是一种“产生冲突机会”和“空间使用”的平衡与折中：加载因子越小，说明空间空置率高，空间使用率小，但是加载因子越大，说明空间利用率上去了，但是“产生冲突机会”高了。

每种哈希表的都会有一个加载因子，数值超过加载因子就会为哈希表扩容。
Golang的map的加载因子的公式是：**map长度 / 2^B**(这是代表bmap数组的长度，B是取的低位的位数)阈值是6.5。其中B可以理解为已扩容的次数。

当Go的map长度增长到大于加载因子所需的map长度时，Go语言就会将**产生一个新的bucket数组**，然后把旧的bucket数组移到一个属性字段**oldbucket**中。

注意：并不是立刻把旧的数组中的元素转义到新的bucket当中，而是，**只有当访问到具体的某个bucket的时候，会把bucket中的数据转移到新的bucket中**。

注意：并不会直接删除旧的bucket，而是**把原来的引用去掉**，利用GC清除内存。

##### **map中数据的删除**

```
1、如果``key``是一个指针类型的，则直接将其置为空，等待GC清除；
2、如果是值类型的，则清除相关内存。
3、同理，对``value``做相同的操作。
4、最后把key对应的高位值对应的数组index置为空。
```

#### 2.sync.map

**并发安全**的map

1. 以空间换效率，通过**read和dirty**两个map来提高读取效率
2. 优先从read map中读取(无锁)，否则再从dirty map中读取(加锁)
3. 动态调整，当misses次数过多时，将dirty map提升为read map
4. 延迟删除，删除只是为value打一个标记，在dirty map提升时才执行真正的删除

`read map` 和 `dirty map` 的**存储方式**是不一致的。

前者使用 **`atomic.Value`**，后者只是单纯的使用 map。原因是 `read map` 使用 `lock free` 操作，必须保证 `load/store` 的**原子性**；而 `dirty map` 的 `load+store` 操作是由 lock（就是 mutex）来保护的。



##### load

1、**首先是 fast path，直接在 read 中找**，如果找到了直接调用 entry 的 load 方法，取出其中的值。
2、如果 read 中没有这个 key，且 amended 为 fase，说明 dirty 为空，那直接返回空和 false。
3、如果 read 中没有这个 key，且 **amended 为 true**，说明 **dirty 中可能存在我们要找的 key**。当然要**先上锁**，再尝试去 dirty 中查找。在这之前，仍然有一个 **double check** 的操作。若还是没有在 read 中找到，那么就从 dirty 中找。不管 dirty 中有没有找到，都要"记一笔"，因为在 dirty 被提升为 read 之前，都会进入这条路。

对于`missLocked`会直接将 misses 的值加 1，表示一次未命中，**如果 misses 值小于 m.dirty 的长度，就直接返回**。否则，将 m.dirty 晋升为 read，并清空 dirty，清空 misses 计数值。这样，之前一段时间新加入的 key 都会进入到 read 中，从而能够提升 read 的命中率。

##### store

1、首先还是**去read map中查询，存在并且p!=expunged,直接修改**。（由于**修改的是 entry 内部的 pointer**，因此 **dirty map 也可见**）
2、如果read map中**存在该key，但p == expunged**。**加锁更新**p的状态，然后直接**更新该entry** (此时m.dirtynil或m.dirty[key]e)
3、如果read map中不存在该Key，但**dirty map中存在该key，直接写入更新entry(read map中仍然没有)**
4、如果read map和dirty map**都不存在该key**

- a. 如果dirty map为空，则需要创建dirty map，并从read map中拷贝未删除的元素
- b. 更新**amended字段，标识dirty map中存在read map中没有的key**
- c. 将k v写入dirty map中，read.m不变

##### delete

1、先去read map中寻找，如果存在就直接删除
2、如果没找到，并且 read.amended为true代表dirty map中存在，依照传统进行 **double check**。
3、read map找到就删除，没找到判断dirty map是否存在，存在了就删除

##### loadorstore

结合了 Load 和 Store 的功能，如果 map 中存在这个 key，那么返回这个 key 对应的 value；否则，将 key-value 存入 map。
这在需要先执行 Load 查看某个 key 是否存在，之后再更新此 key 对应的 value 时很有效，因为 LoadOrStore 可以并发执行。

##### 总结

除了Load/Store/Delete之外，sync.Map还提供了LoadOrStore/Range操作，但没有提供Len()方法，这是因为要统计有效的键值对只能先提升dirty map(dirty map中可能有read map中没有的键值对)，再遍历m.read(由于延迟删除，不是所有的键值对都有效)，这其实就是Range做的事情，因此在不添加新数据结构支持的情况下，sync.Map的长度获取和Range操作是同一复杂度的。这部分只能看官方后续支持。

1、sync.map 是线程安全的，读取，插入，删除也都保持着常数级的时间复杂度。

2、通过**读写分离，降低锁时间来提高效率，适用于读多写少的场景**。

3、Range 操作需要提供一个函数，参数是 k,v，返回值是一个布尔值：f func(key, value interface{}) bool。

4、调用 Load 或 LoadOrStore 函数时，如果在 read 中没有找到 key，则会将 misses 值原子地增加 1，**当 misses 增加到和 dirty 的长度相等时，会将 dirty 提升为 read。以期减少“读 miss”**。

5、**新写入的 key 会保存到 dirty 中**，如果这时 dirty 为 nil，就会先新创建一个 dirty，并将 read 中未被删除的元素拷贝到 dirty。

6、当 dirty 为 nil 的时候，read 就代表 map 所有的数据；**当 dirty 不为 nil 的时候，dirty 才代表 map 所有的数据。**

#### 3.GMP模型

- M结构是Machine，**系统线程**，它由操作系统管理，**goroutine就是跑在M之上的**；M是一个很大的结构，里面维护小对象内存cache（mcache）、当前执行的goroutine、随机数发生器等等非常多的信息。
- P结构是Processor，**处理器(当P有任务时需要创建或者唤醒一个系统线程来执行它队列里的任务。所以P/M需要进行绑定，构成一个执行单元)**，它的主要用途就是用来执行goroutine，它**维护了一个goroutine队列**，即runqueue。Processor的让我们从N:1调度到M:N调度的重要部分。
- G是goroutine实现的核心结构，它包含了栈，指令指针，以及其他对调度goroutine很重要的信息，例如其阻塞的channel。

> Processor的数量是在启动时被设置为环境变量GOMAXPROCS的值，或者通过运行时调度函数GOMAXPROCS()进行设置。Processor数量固定意味着任意时刻只有GOMAXPROCS个线程在运行着go代码

##### 正常情况下

所有的goroutine运行在同一个M系统线程中，每一个M系统线程维护一个Processor，任何时刻，**一个Processor中只有一个goroutine**，其他goroutine在runqueue中**等待**。一个goroutine运行完自己的时间片后，让出上下文，回到runqueue中。 多核处理器的场景下，为了运行goroutines，**每个M系统线程会持有一个Processor**。

如果两个M都在一个CPU上运行，这就是并发；如果两个M在不同的CPU上运行，这就是并行。在正常情况下，scheduler（调度器）会按照上面的流程进行调度，当一个G（goroutine）的时间片结束后将P（Processor）分配给下一个G，但是线程会发生阻塞等情况，看一下goroutine对线程阻塞等的处理。

##### 线程阻塞

当正在运行的goroutine（G0）阻塞的时候，例如进行系统调用，会再创建一个系统线程（M1)，当前的M0线程放弃了它的Processor（P），**P转到新的线程中去运行**。

<img src="校招面经.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3ODU4MzMy,size_16,color_FFFFFF,t_70.png" alt="在这里插入图片描述" style="zoom:67%;" />

##### runqueue执行完成

当其中一个Processor的runqueue为空，没有goroutine可以调度，它会从另外一个上下文偷取一半的goroutine。

<img src="校招面经.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3ODU4MzMy,size_16,color_FFFFFF,t_70-20210217172644817.png" alt="在这里插入图片描述" style="zoom:67%;" />

> 首先创建一个G对象，G对象保存到P本地队列或者是全局队列。P此时去唤醒一个M。P继续执行它的执行序。M寻找是否有空闲的P，如果有则将该G对象移动到它本身。接下来M执行一个调度循环(调用G对象->执行->清理线程→继续找新的Goroutine执行)。
> M执行过程中，随时会发生上下文切换。当发生上线文切换时，需要对执行现场进行保护，以便下次被调度执行时进行现场恢复。Go调度器**M的栈保存在G对象上**，只需要将M所需要的寄存器(SP、PC等)保存到G对象上就可以实现现场保护。当这些寄存器数据被保护起来，就随时可以做上下文切换了，在中断之前把现场保存起来。如果此时G任务还没有执行完，M可以将任务重新丢到P的任务队列，等待下一次被调度执行。当再次被调度执行时，M通过访问G的vdsoSP、vdsoPC寄存器进行现场恢复(从上次中断位置继续执行)。

#### 4.切片和数组

##### 数组

1. Go中的数组是值类型，换句话说，如果你将一个数组赋值给另外一个数组，那么，实际上就是将整个数组拷贝一份。
2. 如果Go中的数组作为函数的参数，那么实际传递的参数是一份数组的拷贝，而不是数组的指针。这个和C要区分开。因此，在Go中如果将数组作为函数的参数传递的话，那效率就肯定没有传递指针高了。
3. array的长度也是Type的一部分，这样就说明[10]int和[20]int是不一样的。在**初始化后长度是固定的**，无法修改其长度。

##### 切片

切片本身并不是动态数组或者数组指针。它内部实现的数据结构**通过指针引用底层数组**，设定相关属性将数据读写操作限定在指定的区域内。**切片本身是一个只读对象，其工作机制类似数组指针的一种封装。**

切片（slice）是对数组一个连续片段的引用，所以切片是一个引用类型（因此更类似于 C/C++ 中的数组类型，或者 Python 中的 list 类型）。这个片段可以是整个数组，或者是由起始和终止索引标识的一些项的子集。需要注意的是，**终止索引标识的项不包括在切片内**。切片提供了一个与指向数组的动态窗口。

给定项的切片索引可能比相关数组的相同元素的索引小。和数组不同的是，**切片的长度可以在运行时修改**，最小为 0 最大为相关数组的长度：切片是一个长度可变的数组。

###### 切片扩容

新的切片和之前的切片已经不同了，因为新的切片更改了一个值，并没有影响到原来的数组，**新切片指向的数组是一个全新的数组**。并且 **cap 容量**也发生了变化。

**扩容的策略**：

**如果切片的容量小于 1024 个元素，于是扩容的时候就翻倍增加容量**。

一旦元素个数**超过 1024 个元素**，那么增长因子就变成 1.25 ，即**每次增加原来容量的四分之一**。

**注意：扩容扩大的容量都是针对原来的切片容量而言的，而不是针对原来数组的长度而言的。**

###### 切片拷贝

有坑，容易在拷贝之后仍旧指向原数组，造成可以修改原数组。

#### 5.GC

##### 垃圾回收常见方法

###### **引用计数（reference counting）**

通过在对象上增加自己被引用的次数，被其他对象引用时加1，引用自己的对象被回收时减1，引用数为0的对象即为可以被回收的对象。这种算法在内存比较紧张和实时性比较高的系统中使用的比较广泛，如ios cocoa框架，php，python等。

优点：方式简单，回收速度快。

缺点：

1. 需要额外的空间存放计数。
2. 无法处理循环引用（如a.b=b;b.a=a这种情况）。
3. 频繁更新引用计数降低了性能。

**标记-清除（mark and sweep）**

该方法分为两步，标记从根变量开始迭代得遍历所有被引用的对象，**对能够通过应用遍历访问到的对象都进行标记为“被引用”**；标记完成后进行清除操作，**对没有标记过的内存进行回收**（回收同时可能伴有碎片整理操作）。

这种方法解决了引用计数的不足，但是也有比较明显的问题：**每次启动垃圾回收都会暂停当前所有的正常代码执行，回收时系统响应能力大大降低**！当然后续也出现了很多mark&sweep算法的变种（如三色标记法）优化了这个问题。

**复制收集**

复制收集的方式只需要对对象进行一次扫描。准备一个「**新的空间**」，从根开始，对对象进行扫，如果存在对这个对象的引用，就把它复制到「新空间中」。**一次扫描结束之后，所有存在于「新空间」的对象就是所有的非垃圾对象。**

这两种方式各有千秋，**标记清除的方式节省内存但是两次扫描需要更多的时间，对于垃圾比例较小的情况占优势。复制收集更快速但是需要额外开辟一块用来复制的内存，对垃圾比例较大的情况占优势。**特别的，复制收集有「**局部性**」的优点。

在复制收集的过程中，会按照对象**被引用的顺序**将对象复制到新空间中。于是，**关系较近的对象被放在距离较近的内存空间的可能性会提高**，这叫做局部性。局部性高的情况下，内存缓存会更有效地运作，程序的性能会提高。

对于标记清除，有一种**标记-压缩**算法的衍生算法：

对于压缩阶段，它的工作就是移动所有的可达对象到堆内存的同一个区域中，使他们紧凑的排列在一起，从而将所有非可达对象释放出来的空闲内存都集中在一起，通过这样的方式来达到**减少内存碎片**的目的。

**分代收集（generation）**

这种收集方式用了程序的一种特性：大部分对象会从产生开始在很短的时间内变成垃圾，而存在的很长时间的对象往往都有较长的生命周期。

根据对象的存活周期不同将内存划分为新生代和老年代，**存活周期短的为新生代，存活周期长的为老年代**。这样就可以根据每块内存的特点采用最适当的收集算法。

新创建的对象存放在称为 新生代（young generation）中（一般来说，新生代的大小会比 老年代小很多）。**高频对新生成的对象进行回收，称为「小回收」，低频对所有对象回收，称为「大回收」**。每一次「小回收」过后，就把存活下来的对象归为老年代，「小回收」的时候，遇到老年代直接跳过。大多数分代回收算法都采用的「复制收集」方法，因为小回收中垃圾的比例较大。

这种方式存在一个问题：如果在某个新生代的对象中，存在「老生代」的对象对它的引用，它就不是垃圾了，那么怎么制止「小回收」对其回收呢？这里用到了一中叫做写屏障的方式。

**程序对所有涉及修改对象内容的地方进行保护，被称为「写屏障」（Write Barrier）。写屏障不仅用于分代收集，也用于其他GC算法中。**

在此算法的表现是，用一个**记录集**来记录从新生代到老生代的引用。如果有两个对象A和B，当对A的对象内容进行修改并加入B的引用时，如果①A是「老生代」②B是「新生代」。则将这个引用加入到记录集中。「小回收」的时候，因为记录集中有对B的引用，所以B不再是垃圾。

##### 三色标记算法

三色标记算法是对标记阶段的改进，原理如下：

1. 起初所有对象都是**白色**。
2. 从根出发扫描**所有可达对象，标记为灰色**，放入待处理队列。
3. 从队列取出灰色对象，将**其引用对象标记为灰色放入队列**，**自身标记为黑色**。
4. 重复 3，**直到灰色对象队列为空**。此时白色对象即为垃圾，进行回收。

三色标记的一个明显好处是**能够让用户程序和 mark 并发的进行**。

##### GO的垃圾回收器

总体采用的是经典的**mark and sweep**算法。

- v1.3以前版本 **STW**（Stop The World）

    go runtime在一定条件下（内存超过阈值或定期如2min），暂停所有任务的执行，进行mark&sweep操作，操作完成后启动所有任务的执行。在内存使用较多的场景下，go程序在进行垃圾回收时会发生非常明显的卡顿现象（Stop The World）。

- v1.3 **Mark STW, Sweep** 并行

    1.3版本中，go runtime**分离了mark和sweep操作**，和以前一样，也是先暂停所有任务执行并启动mark，mark完成后马上就重新启动被暂停的任务了，让sweep任务和普通协程任务一样并行的和其他任务一起执行。如果运行在多核处理器上，go会试图将gc任务放到单独的核心上运行而尽量不影响业务代码的执行。go team自己的说法是减少了50%-70%的暂停时间。

- v1.5 **三色标记法**

    go 1.5正在实现的垃圾回收器是“非分代的、非移动的、并发的、三色的标记清除垃圾收集器”。这种方法的**mark操作是可以渐进执行的而不需每次都扫描整个内存空间**，可以**减少stop the world的时间**。

- v1.8 **混合写屏障**（hybrid write barrier）

    **采用一种混合的 write barrier 方式来避免堆栈重新扫描。**

    混合屏障的优势在于它**允许堆栈扫描永久地使堆栈变黑**（没有STW并且没有写入堆栈的障碍），这**完全消除了堆栈重新扫描的需要**，从而消除了对堆栈屏障的需求。重新扫描列表。特别是堆栈障碍在整个运行时引入了显着的复杂性，并且干扰了来自外部工具（如GDB和基于内核的分析器）的堆栈遍历。

    混合屏障不需要读屏障，因此指针读取是常规的内存读取; 它确保了进步，因为物体单调地从白色到灰色再到黑色。

    混合屏障的缺点很小。它可能会导致更多的浮动垃圾，**因为它会在标记阶段的任何时刻保留从根（堆栈除外）可到达的所有内容。**然而，在实践中，当前的Dijkstra障碍可能几乎保留不变。混合屏障还禁止某些优化：特别是，如果Go编译器可以静态地显示指针是nil，则Go编译器当前省略写屏障，但是在这种情况下混合屏障需要写屏障。这可能会略微增加二进制大小。

**小结：**

通过go team多年对gc的不断改进和忧化，GC的卡顿问题在1.8 版本基本上可以做到 1 毫秒以下的 GC 级别。 实际上，**gc低延迟是有代价的，其中最大的是吞吐量的下降**。由于需要**实现并行处理，线程间同步和多余的数据生成复制都会占用实际逻辑业务代码运行的时间**。GHC的全局停止GC对于实现高吞吐量来说是十分合适的，而Go则更擅长与低延迟。
并行**GC的第二个代价是不可预测的堆空间扩大**。程序在GC的运行期间仍能不断分配任意大小的堆空间，因此我们需要在到达最大的堆空间之前实行一次GC，但是过早实行GC会造成不必要的GC扫描，这也是需要衡量利弊的。因此在使用Go时，需**要自行保证程序有足够的内存空间**。

##### GC流程

GO的GC是并行GC, 也就是**GC的大部分处理和普通的go代码是同时运行**的, 这让GO的GC流程比较复杂.

1. Stack scan：收集根对象（全局变量，和G stack），开启写屏障。全局变量、开启写屏障需要STW，G stack只需要停止该G就好**，时间比较少。
2. Mark: 标记所有根对象**, **和根对象可以到达的所有对象不被回收**。
3. Mark Termination: **重新扫描全局变量，和上一轮改变的stack（写屏障），完成标记工作。这个过程需要STW**。
4. Sweep: **按标记结果清扫span**

目前整个GC流程会进行两次STW(Stop The World), 第一次是Stack scan阶段, 第二次是Mark Termination阶段.

第一次STW会准备根对象的扫描, 启动写屏障(Write Barrier)和辅助GC(mutator assist).

第二次STW会重新扫描部分根对象, 禁用写屏障(Write Barrier)和辅助GC(mutator assist).

##### 写屏障

因为go支持**并行GC**, GC的扫描和go代码可以同时运行, 这样带来的问题是**GC扫描的过程中go代码有可能改变了对象的依赖树。**

例如开始扫描时发现根对象A和B, B拥有C的指针。

1. GC先扫描A，A放入黑色
2. B把C的指针交给A
3. GC再扫描B，B放入黑色
4. C在白色，会回收；但是A其实引用了C。

为了避免这个问题, **go在GC的标记阶段会启用写屏障**(Write Barrier).

启用了写屏障(Write Barrier)后，在GC第三轮rescan阶段，根据写屏障标记将C放入灰色，防止C丢失。

#### 6.sync pool的实现原理

用来保存和复用临时对象，以减少内存分配，降低CG压力。

#### 7.map里面解决hash冲突怎么做的，冲突了元素放在头还是尾

#### 8.channel有无缓冲槽的区别，主要还是从同步和异步来讲

#### 9.slice的底层实现

#### 10.Java和go的共同点和区别

#### 11.go的优势

#### 12.怎么限制gouroutine的数量？

带缓冲的chan通道，chan满了就阻塞。

优雅：做一个goroutine池，同时加入waitgroup，等待所有结束了再退出。

#### 14.go内存分配机制

#### 15.go的多态实现

#### 16.interface的底层实现

#### 17.golang的context包

#### 18.string类型转为[]byte发生了什么？

#### 19.Golang的多路复用

#### 20.Golang调度，能不能不要p？

#### 21.实现一个压测工具

golang编写一个http客户端，支持参数http request -c 5 -r 1000 http://**** 客户端，输出所有响应

#### 22.map怎么实现顺序读取？

空间换时间
借助额外的数据结构比如slice 等，对key进行排序，遍历slice得到顺序输出

#### 23.协程泄漏

如果你启动了一个 **goroutine，但并没有符合预期的退出**，直到程序结束，此goroutine才退出，这种情况就是 goroutine 泄露。当 goroutine 泄露发生时，该 goroutine 的栈(一般 2k 内存空间起)一直被占用不能释放，goroutine 里的函数在堆上申请的空间也不能被垃圾回收器回收。

#### 24.空结构体的用处

空结构体不占用内存空间

1. 实现set
2. 实现chan struct{} 不占用内存空间，实现传递信号的通道

#### 25.Go的Mutex和RWmutex及实现原理

#### 26.HashMap是怎么添加元素的？

#### 27.TreeMap和HashMap的区别

#### 28.Go怎么做深拷贝？

#### 29.defer的执行顺序

#### 30.切片怎么扩容，扩容过程需不需要重新写入

#### 31.Go的协程可不可以自己让出CPU

#### 32.Go的协程只能挂在一个线程上面吗？

#### 33.切片和数组区别和底层

#### 34.defer，recover，Panic执行顺序

#### 35.Channel在什么情况下会Panic？

#### 36.什么情况下 M 会进入自旋的状态？

M 是系统线程。为了保证自己不被释放，所以自旋。这样一旦有 G 需要处理，M 可以直接使用，不需要再创建。M 自旋表示此时没有 G 需要处理。

#### 37.syncLock和channel的性能对比

#### 38.内存分配的不同方法的优缺点，Go的内存分配

固定分区、动态分区、页式分配

#### 39.Golang slice 不断 append，是如何给它分配内存的？slice 如果分配的 capacity 是 10，那当容量到多大的时候才会扩容？8、9、10？

#### 40.面向对象的几个特性

#### 41.什么是多态，泛型

#### 42.slice，map都是安全的吗？

#### 43.线程安全的map锁分段的细节

#### 44.hash表是如何实现的扩容

#### 45.上下文切换的细节

#### 46.如何让n个线程执行完后一起结束？

#### 47.如何实现一个锁

#### 48.上层协程结束了，如何通知子协程也结束？

#### 49.协程的栈空间大小有限制吗？会主动扩展吗？

#### 50.Golang context应用场景

#### 51.Context的数据结构(树)

#### 52.WaitGroup

#### 53.Go的性能问题怎么排查？(profile)



### 2.计算机网络

#### 1.tcp三握四挥

**TCP 建立连接：三次握手**

1. client: syn
2. server: syn+ack
3. client: ack

**TCP 断开连接：四次挥手**

1. client: fin
2. server: ack
3. server: fin
4. client: ack

#### 2.syn flood

讲的挺好的一篇文章

https://blog.csdn.net/qq_34777600/article/details/81946514

##### TCP攻击三类：

 1.**FLOOD类攻击**，例如**发送海量的syn,syn_ack,ack,fin等报文**，占用服务器资源，使之无法提供服务。

 2.**连接耗尽类攻击**，如与被攻击方，完成三次握手后不再发送报文一直维持连接，或者立刻发送FIN或RST报文，断开连接后再次快速发起新的连接等，**消耗TCP连接资源**。 

3.**利用协议特性攻击**：例如攻击这建好连接之后，基于TCP的流控特性，立马就**把TCP窗口值设为0**，然后断开连接，则服务器就要等待Windows开放，造成资源不可用。或者发送异常报文，可能造成被攻击目标崩溃。

Syn-Flood攻击是当前网络上最为常见的DDoS攻击，也是最为经典的拒绝服务攻击，它利用了TCP协议实现上的一个缺陷，通过**向网络服务所在端口发送大量的伪造源地址的攻击报文**，就可能造成目标服务器中的**半开连接队列被占满**，从而阻止其他合法用户进行访问。

它的数据包特征通常是，源发送了大量的SYN包，并且**缺少三次握手的最后一步握手ACK回复**。

#####  flood防御

###### cookie源认证

原理是syn报文首先**由DDOS防护系统来响应syn_ack**。带上特定的 sequence number （记为cookie）。真实的客户端会返回一个ack 并且 Acknowledgment number 为 cookie+1。 而伪造的客户端，将不会作出响应。这样我们就可以知道那些IP对应的客户端是真实的，将真实客户端IP加入白名单。下次访问直接通过，而其他伪造的syn报文就被拦截。

###### **reset认证**

Reset认证利用的是TCP协议的可靠性，也是首先由DDOS防护系统来响应syn。防护设备收到syn后响应syn_ack,将Acknowledgement number (确认号)设为特定值（记为cookie）。当真实客户端收到这个报文时，发现确认号不正确，将发送reset报文，并且sequence number 为cookie + 1。 而伪造的源，将不会有任何回应。这样我们就可以将真实的客户端IP加入白名单。

###### TCP首包丢弃

该算法利用了TCP/IP协议的重传特性，来自某个源IP的第一个syn包到达时被直接丢弃并记录状态(五元组)，在该源IP的第2个syn包到达时进行验证，然后放行。

当防御设备接到一个IP地址的SYN报文后:

1. 接受到syn报文   -> 简单比对该IP是否存在于白名单中:  存在则转发到后端，否则进行第2步
2. 不存在于白名单中 -> 检查是否是该IP在一定时间段内的首次SYN报文： 不是则进行第3步，是则进行第5步
3. 不是首次SYN报文 -> 检查是否重传报文： 是重传则转发并加入白名单，不是则丢弃并加入黑名单
4. 是首次SYN报文  -> 丢弃并等待一段时间以试图接受该IP的SYN重传报文，等待超时则判定为攻击报文加入黑名单。

###### TCP代理

首包丢弃方案对用户体验会略有影响，因为丢弃首包重传会增大业务的响应时间，有鉴于此发展出了一种更优的**TCP Proxy方案**。所有的SYN数据报文**由清洗设备接受**，按照SYN Cookie方案处理。和设备成功建立了TCP三次握手的IP地址被判定为合法用户加入白名单，由设备伪装真实客户端IP地址再与真实服务器完成三次握手，随后转发数据。而指定时间内没有和设备完成三次握手的IP地址，被判定为恶意IP地址屏蔽一定时间。除了SYN Cookie结合TCP Proxy外，清洗设备还具备多种畸形TCP标志位数据包探测的能力，通过对SYN报文返回非预期应答测试客户端反应的方式来鉴别正常访问和恶意行为。

#### 3.syn cookie

SYN Cookie是对TCP服务器端的三次握手做一些修改，专门用来防范SYN Flood攻击的一种手段。它的原理是，在TCP服务器接收到TCP SYN包并返回TCP SYN + ACK包时，不分配一个专门的数据区，而是根据这个SYN包计算出一个cookie值。这个cookie作为将要返回的SYN ACK包的初始序列号。当客户端返回一个ACK包时，根据包头信息计算cookie，与返回的确认序列号(初始序列号 + 1)进行对比，如果相同，则是一个正常连接，然后，分配资源，建立连接。

#### 4.登录过程：cookie session机制

客户端请求服务器，如果服务器需要记录该用户状态，就向客户端浏览器发一个cookie。客户端浏览器会把cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该cookie一同提交给服务器。服务器检查该cookie，以此来辨认用户状态。
session是另一种记录客户状态的机制，不同的是cookie保存在客户端浏览器中，而session保存在服务器上。客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上，这就是session。客户端浏览器再次访问时只需要从该session中查找该客户的状态就可以了。**session相当于程序在服务器上建立的一份用户的档案，用户来访的时候只需要查询用户档案表就可以了。**

虽然session保存在服务器，但是它的正常运行仍然需要客户端浏览器的支持。这是因为**session需要使用cookie作为识别标志**。HTTP协议是无状态的，session不能依据HTTP连接来判断是否为同一客户，因此服务器向客户端浏览器发送一个名为SESSIONID的cookie，它的值为该Session的id。Session依据该cookie来识别是否为同一用户。

对于不支持cookie的手机浏览器，有另一种解决方案：URL地址重写。**URL地址重写的原理是将该用户session的id信息重写到URL地址中，服务器能够解析重写后的URL获取session的id**。这样即使客户端不支持cookie，也可以使用session来记录用户状态。

#### 5.四次挥手，为什么要多中间两次？

因为断开链接的时候，仍可能有数据仍在继续发送，需要确保发送方的数据发出并已被成功接受，还有就是如果缺少中间两次，被动断开方并不知道主动断开方是否收到自己的响应，如果ack包丢失，发起断开方将继续发送消息，而由于被动方已经断开，无法收到，主动方将重复发送fin包，并维持连接状态，占用大量的资源。

#### 6.TCP可靠传输，怎么实现？

1. 应用数据被**分割**成 TCP 认为最适合发送的**数据块**。
2. TCP 给发送的每一个**包进行编号**，接收方对数据包进行排序，把有序数据传送给应用层。
3. **校验和：** TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。
4. TCP 的接收端会**丢弃重复**的数据。
5. **流量控制：** TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用**滑动窗口**实现流量控制）
6. **拥塞控制：** 当网络拥塞时，减少数据的发送。
7. **ARQ 协议：** 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
8. **超时重传：** 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

#### 7.TCP半连接状态

##### 半开连接

 从协议的角度讲，TCP的半开连接是指**TCP连接的一端异常崩溃，或者在未通知对端的情况下关闭连接**，这种情况下不可以正常收发数据，否则会产生RST。比如一个常见的情况是TCP连接的一端异常断电，就会导致TCP的半开连接。**如果没有数据传输，对端就不会知道本端的异常而一直处于ESTABLISHED状态**(TCP有存活检测机制)。

另外从linux实现的角度来说，因为**linux内部有个半连接队列**，TCP半开连接是指发送了TCP连接请求，等待对方应答的状态，此时连接并没有完全建立起来,双方还无法进行通信交互的状态，此时就称为半连接。由于一个完整的TCP连接需要经过三次握手才能完成,这里**把三次握手之前的连接都称之为半连接**。

##### 半关连接

 TCP的半关连接是指**TCP连接只有一方发送了FIN，另一方没有发出FIN包，仍然可以在一个方向上正常发送数据。**

#### 8.http头部

##### 通用首部字段

|    首部字段名     |                    说明                    |
| :---------------: | :----------------------------------------: |
| **Cache-Control** |             控制**缓存**的行为             |
|    Connection     | 控制不再转发给代理的首部字段、管理持久连接 |
|       Date        |           创建报文的**日期**时间           |
|      Pragma       |                报文**指令**                |
|      Trailer      |             报文末端的首部一览             |
| Transfer-Encoding |         指定报文主体的传输编码方式         |
|      Upgrade      |               升级为其他协议               |
|        Via        |            代理服务器的相关信息            |
|      Warning      |                  错误通知                  |

##### 请求首部字段

|     首部字段名      |                      说明                       |
| :-----------------: | :---------------------------------------------: |
|     **Accept**      |        **用户**代理可处理的**媒体类型**         |
|   Accept-Charset    |                  优先的字符集                   |
|   Accept-Encoding   |                 优先的内容编码                  |
|   Accept-Language   |             优先的语言（自然语言）              |
|  **Authorization**  |      **Web 认证信息**（可存放 **Token**）       |
|       Expect        |              期待服务器的特定行为               |
|        From         |               用户的电子邮箱地址                |
|      **Host**       |               请求资源所在服务器                |
|    **If-Match**     |              比较实体标记（ETag）               |
|  If-Modified-Since  |               比较资源的更新时间                |
|    If-None-Match    |        比较实体标记（与 If-Match 相反）         |
|      If-Range       |      资源未更新时发送实体 Byte 的范围请求       |
| If-Unmodified-Since | 比较资源的更新时间（与 If-Modified-Since 相反） |
|    Max-Forwards     |                 最大传输逐跳数                  |
| Proxy-Authorization |         代理服务器要求客户端的认证信息          |
|        Range        |               实体的字节范围请求                |
|     **Referer**     |          对请求中 URI 的**原始获取方**          |
|         TE          |                传输编码的优先级                 |
|     User-Agent      |              HTTP 客户端程序的信息              |

##### 响应首部字段

|      首部字段名      |             说明             |
| :------------------: | :--------------------------: |
|    Accept-Ranges     |   是否接受字节**范围请求**   |
|       **Age**        |   推算资源**创建**经过时间   |
|       **ETag**       |      资源的**匹配信息**      |
|       Location       |   令客户端重定向至指定 URI   |
|  Proxy-Authenticate  | 代理服务器对客户端的认证信息 |
|     Retry-After      |   对再次发起请求的时机要求   |
|      **Server**      |  HTTP 服务器的**安装信息**   |
|       **Vary**       | 代理**服务器缓存**的管理信息 |
| **WWW-Authenticate** | 服务器对客户端的**认证信息** |

##### 实体首部字段

|    首部字段名    |            说明             |
| :--------------: | :-------------------------: |
|    **Allow**     | 资源可**支持的 HTTP 方法**  |
| Content-Encoding |   实体主体适用的编码方式    |
| Content-Language |     实体主体的自然语言      |
|  Content-Length  | 实体主体部分的大小（bites） |
| Content-Location |     替代对应资源的 URI      |
|   Content-MD5    |     实体主体的报文摘要      |
|  Content-Range   |     实体主体的位置范围      |
|   Content-Type   |     实体主体的媒体类型      |
|   **Expires**    | 实体主体**过期的日期**时间  |
|  Last-Modified   |   资源的最后修改日期时间    |

#### 9.长连接和短链接(怎么实现的、区别以及应用场景)

##### 短连接

```
连接->传输数据->关闭连接
比如HTTP是无状态的的短链接，浏览器和服务器每进行一次HTTP操作，就建立一次连接，但任务结束就中断连接。
因为连接后接收了数据就断开了，所以每次数据接受处理不会有联系。 这也是HTTP协议无状态的原因之一。
```

##### 长连接

1. 连接->传输数据->保持连接 -> 传输数据-> ...........->直到一方关闭连接，多是客户端关闭连接。
2. 长连接指建立SOCKET连接后不管是否使用都保持连接，但安全性较差。

##### 应用场景

**长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况**。每个TCP连接都需要三步握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，再次处理时直接发送数据包就OK了，不用建立TCP连接。例如：**数据库**的连接用长连接， 如果用短连接频繁的通信会造成socket错误，而且频繁的socket 创建也是对资源的浪费。

而像**WEB网站的http服务一般都用短链接**，因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以**并发量大，但每个用户无需频繁操作**情况下需用短连好。

##### **TCP的keep alive和HTTP的Keep-alive**

TCP的keep alive是检查当前TCP连接是否活着；HTTP的Keep-alive是要让一个TCP连接活久点。

HTTP长连接之后的好处，包括可以使用**HTTP 流水线技术**（管道化连接），它是指，**在一个TCP连接内，多个HTTP请求可以并行，下一个HTTP请求在上一个HTTP请求的应答完成之前就发起。**

#### 10.http和https的区别，https建立连接的过程

##### http和https

**端口** ：HTTP 的 URL由“http://”起始且默认使用端口 **80**，而 HTTPS 的 URL 由“https://”起始且默认使用端口 **443**。

**安全性和资源消耗：** HTTP 协议运行在 TCP 之上，所有传输的内容都是**明文**，客户端和服务器端都**无法验证对方的身份**。HTTPS 是运行在 **SSL/TLS** 之上的 HTTP 协议，**SSL/TLS 运行在 TCP** 之上。所有传输的内容都经过**加密**，加密采用**对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密**。所以说，HTTP 安全性没有 HTTPS 高 ，但是 HTTPS 比 HTTP 耗费更多服务器资源。

##### https建立连接过程

一个 HTTPS 请求实际上包含了**两次 HTTP** 传输，可以细分为 8 步。

1.客户端向服务器发起 **HTTPS 请求**，连接到服务器的 **443 端口**。

2.服务器端有一个密钥对，即**公钥和私钥**，是用来进行非对称加密使用的，**服务器端保存着私钥**，不能将其泄露，公钥可以发送给任何人。

3.服务器将自己的**公钥发送给客户端**。

4.客户端收到服务器端的公钥之后，会对**公钥进行检查**，验证其**合法性**，如果发现发现公钥有问题，那么 HTTPS 传输就无法继续。严格的说，这里应该是**验证服务器发送的==数字证书==的合法性**，关于客户端如何验证数字证书的合法性，上文已经说明。如果**公钥合格**，那么**客户端**会生成一个**随机值**，这个随机值就是用于进行对称加密的**密钥**，我们将该密钥称之为 client key，即**客户端密钥**，这样在概念上和服务器端的密钥容易进行区分。然后用服务器的**公钥**对**客户端密钥进行==非对称加密==**，这样客户端密钥就变成密文了，至此，HTTPS 中的第一次 HTTP 请求结束。

5.**客户端**会发起 HTTPS 中的**第二个** HTTP 请求，将**加密之后的客户端密钥发送给服务器**。

6.服务器接收到客户端发来的密文之后，会用自己的**私钥**对其进行**非对称解密**，解密之后的明文就是**客户端密钥**，然后用客户端密钥对数据进行==**对称加密**==，这样数据就变成了**密文**。

7.然后服务器将**加密后的密文**发送给客户端。

8.客户端收到服务器发送来的密文，用客户端密钥对其进行对称解密，得到服务器发送的数据。这样 HTTPS 中的第二个 HTTP 请求结束，整个 HTTPS 传输完成。

#### 11.http1.0，1.1和2.0的区别

##### 1.1相比于1.0

进行了**网络和带宽的优化**，增加了更多**缓存处理**策略，增加**新的错误状态码**，host头处理，**支持长连接**。

##### 2.0相比1.1

- **新的二进制格式**（Binary Format），HTTP1.x的解析是**基于文本**。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。
- **多路复用**（MultiPlexing），即**连接共享**，即每一个request都是是用作连接共享机制的。一个request对应一个id，这样**一个连接上可以有多个request**，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。
- **header压缩**，如上文中所言，对前面提到过HTTP1.x的header带有大量信息，而且每次都要重复发送，**HTTP2.0使用encoder来减少需要传输的header大小**，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。
- **服务端推送**（server push）。例如网页有一个sytle.css的请求，在客户端收到sytle.css数据的同时，服务端会将sytle.js的文件推送给客户端，当客户端再次尝试获取sytle.js时就可以直接从缓存中获取到，不用再发请求了。

#### 12.网络七层模型和五层模型

##### OSI七层模型

应用层：各种应用程序协议，http,FTP,SMTP等

表示层：信息语法语义关联。如加密解密、压缩解压缩等

会话层：不同机器的用户建立会话及管理

传输层：接受上层的数据，必要的时候进行分割，交给网络层传输

网络层：控制子网的运行，如逻辑分组，路由分组转发等

数据链路层：物理寻址，将原始比特流转换为逻辑传输线路

物理层：物理通信设备上原始比特流传输

##### 五层模型

-  **应用层** ：**为特定应用程序提供数据传输服务**，例如 **HTTP、DNS 等协议**。数据单位为报文。
-  **传输层** ：**为进程提供通用数据传输服务**。由于应用层协议很多，定义通用的传输层协议就可以支持不断增多的应用层协议。运输层包括两种协议：传输控制协议 **TCP**，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 **UDP**，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提供完整性服务，UDP 主要提供及时性服务。
-  **网络层** ：**为主机提供数据传输服务**。而传输层协议是为主机中的进程提供数据传输服务。网络层把传输层传递下来的报文段或者用户数据报封装成分组。在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。网络层协议主要有 **IP （网际互连协议），ARP （地址解析）协议**等。
-  **数据链路层** ：针对的还是**主机之间的数据传输**服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。链路层协议有 **PPP 协议、CSMA/CD 协议**等。
-  **物理层** ：**考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体**。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。

#### 13.TCP拥塞控制

在某段时间，若对网络中某资源的需求超过了该资源所能提供的可用部分，网络的**性能**就要变坏。这种现象称为**拥塞** (congestion)。

解决拥塞问题的**两条思路**：

- 增加网络可用资源；
- 减少用户对资源的需求。

**拥塞控制**：基于**拥塞窗口变量+几种拥塞控制算法**实现。 

##### 拥塞控制算法

###### 慢开始

**目的**：用来确定网络的负载能力或拥塞程度。

**算法的思路**：由小到大**逐渐**增大拥塞窗口数值，直到窗口门限。

**cwnd = cwnd * 2***

###### 拥塞避免

###### 快重传

- **发送方**只要一连收到**三个重复确认**，就知道接收方确实**没有收到**报文段，因而应当**立即进行重传**（即“**快重传**”），这样就不会出现超时，发送方也不就会误认为出现了网络拥塞。
- 使用快重传可以使整个网络的**吞吐量**提高约 20%。 
- 不难看出，快重传并非取消重传计时器，而是在某些情况下可以**更早地（更快地）重传**丢失的报文段。 
- 采用**快重传 FR** (Fast Retransmission) 算法可以让**发送方**尽早知道发生了个别报文段的丢失。
- 快重传算法首先要求接收方**不要等待**自己发送数据时才进行捎带确认，而是要**立即发送确认**，即使收到了**失序**的报文段也要**立即**发出对已收到的报文段的**重复确认**。

###### 快恢复

当发送端收到连续三个重复的确认时，由于发送方现在认为网络**很可能==没有==发生拥塞**，因此现在**不需要**执行慢开始算法，而是执行**快恢复算法** FR (Fast Recovery) 算法：

**（1）慢开始门限 ssthresh = 当前拥塞窗口 cwnd / 2 ；**
**（2）新拥塞窗口 cwnd = 慢开始门限 ssthresh ；**
**（3）开始执行拥塞避免算法，使拥塞窗口缓慢地线性增大。** 

#### 14.ping指令的实现，涉及到哪些协议

向指定的IP地址发送一定长度的数据包，按照约定，若指定IP地址存在的话，会返回同样大小的数据包，当然，若在特定的时间内没有返回，就是“超时”，就认为指定的IP不存在。

由于ping使用的是**ICMP协议**，有些防火墙会屏蔽ICMP协议，所以有时候ping的结果只能作为参考，ping不通并不一定说明对方IP不存在。

#### 15.tcp的粘包问题

发送端为了将多个发往接收端的包，更加高效的的发给接收端，于是采用了优化算法（Nagle算法），**将多次间隔较小、数据量较小的数据，合并成一个数据量大的数据块，然后进行封包**。那么这样一来，接收端就必须使用高效科学的拆包机制来分辨这些数据。

##### 造成TCP粘包的原因

**发送方原因**

TCP默认使用Nagle算法（主要作用：减少网络中报文段的数量），而Nagle算法主要做两件事：

1. 只有上一个分组得到确认，才会发送下一个分组
2. 收集多个小分组，在一个确认到来时一起发送

Nagle算法造成了发送方可能会出现粘包问题

**接收方原因**

TCP接收到数据包时，并不会马上交到应用层进行处理，或者说应用层并不会立即处理。实际上，**TCP将接收到的数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组**。这样一来，如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。

##### 如何处理粘包？

**发送方**

对于发送方造成的粘包问题，可以通过**关闭Nagle算法**来解决，使用**TCP_NODELAY**选项来关闭算法。

**接收方**

接收方没有办法来处理粘包现象，只能将问题交给应用层来处理。

**应用层**

应用层的解决办法简单可行，不仅能解决接收方的粘包问题，还可以解决发送方的粘包问题。

解决办法：循环处理，应用程序从接收缓存中读取分组时，**读完一条数据，就应该循环读取下一条数据，直到所有数据都被处理完成**，但是如何判断每条数据的长度呢？

1. **格式化数据**：每条数据有固定的格式（开始符，结束符），这种方法简单易行，但是选择开始符和结束符时一定要确保每条数据的内部不包含开始符和结束符。
2. **发送长度**：发送每条数据时，将数据的长度一并发送，例如规定数据的前4位是数据的长度，应用层在处理时可以根据长度来判断每个分组的开始和结束位置。

#### 16.https的过程？

1. 客户端请求网址，服务器接收到请求后返回证书公钥 
2. 客户端验证证书的有效性和合法性，然后生成一个随机值 
3. 客户端通过证书的公钥加密随机值，将加密后的密钥发送给服务器 
4. 服务器通过私钥解密密钥，通过解密后的密钥加密要发送的内容 
5. 客户端通过密钥解密接受的内容

#### 17.http keep-alive作用

使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive功能避免了建立或者重新建立连接。可以一次连接多次请求。

#### 18.fasthttp为什么快？

它的高性能主要源自于“复用”，通过服务协程和内存变量的复用，节省了大量资源分配的成本。

##### 工作协程的复用

worker协程和连接协程之间通过channel通信，内部维护了一个ready状态的channel列表，**连接协程收到新的conn以后，找到空闲的channel，把连接通过channel交给相应的worker**，worker协程处理完当前连接后把channel归还到空闲列表等待下一个请求。

##### 内存变量复用 

fasthttp内部大量使用了sync.Pool，为多次使用的变量**节省了大量的内存申请开销**，我们举最常用的RequestCtx为例，每次的请求开始时，先在ctxPool中查找可复用的ctx变量，请求完成以后，把变量归还到Pool中。

当然，这样的复用实际上可能会给使用者带来额外的学习成本，**RequestCtx变量不能在handle函数以外的地方使用**，例如如果我们要做一些**异步的操作时，必须把所需的数据拷贝出来给到新的协程**，否则会出现无法预知的并发错误，这一点一定要切记。

#### 19.http2.0的多路复用怎么实现的？

在一个HTTP的连接上，多路“HTTP消息”同时工作。

HTTP/2设计是基于“二进制帧”进行设计的，这种设计无疑是一种“高超的艺术”，因为它实现了一个目的：一切可预知，一切可控。帧是一个数据单元，实现了**对消息的封装**。帧的字节中保存了不同的信息，前9个字节对于每个帧都是一致的，“服务器”解析HTTP/2的数据帧时只需要解析这些字节，就能准确的知道整个帧期望多少字节数来进行处理信息。如果使用HTTP/1.1的话，你需要发送完上一个请求，才能发送下一个；**由于HTTP/2是分帧的，请求和响应可以交错甚至可以复用**。

“流”的概念：**HTTP/2连接上独立的、双向的帧序列交换。流ID（帧首部的6-9字节）用来标识帧所属的流**。

#### 20.DNS基于什么协议，有没有基于http的DNS协议？

DNS在区域传输的时候使用TCP协议，其他时候使用UDP协议。

**DNS区域传输的时候使用TCP协议：**

1.辅域名服务器会**定时（一般3小时）向主域名服务器进行查询**以便了解数据是否有变动。如有变动，会执行一次区域传送，进行数据同步。区域传送使用TCP而不是UDP，因为数据同步传送的数据量比一个请求应答的数据量要多得多。

2.TCP是一种**可靠连接，保证了数据的准确性**。

**域名解析时使用UDP协议：**

**客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可**。不用经过三次握手，这样DNS服务器负载更低，响应更快。

##### 基于http的DNS解析器

HTTPDNS 其实就是自己搭建了一套DNS ，不用传统的DNS 解析了。HTTPDNS 是基于HTTP 协议的DNS 服务器集群，分布在多个地点和运营商。当客户端需要DNS 解析的时候，直接通过HTTP协议进行请求这个服务器集群，得到就近的地址。

HTTPDNS 相当于每个客户端，都有自己的域名解析。自己做一个自己的地址簿，而不使用统一的地址簿。

 HTTPDNS 在解析的过程中，不像老DNS 协议那样递归调用一圈，一个HTTP的请求就能搞定，要实时更新的时候，马上就能起作用。HTTPDNS 的缓存设计为三层，分为：**客户端、缓存、数据源**三层。

#### 21.什么是网关？网关的作用

网关**在网络层以上实现网络互连**，是最复杂的网络互连设备，仅用于两个高层协议不同的网络互连。

是一种充当转换重任的计算机系统或设备。使用在不同的通信协议、数据格式或语言，甚至体系结构完全不同的两种系统之间，网关是一个**翻译器**。与网桥只是简单地传达信息不同，网关**对收到的信息要重新打包，以适应目的系统的需求**。

#### 22.Http的方法，GET和POST区别，HTTP状态码，502和504的区别

|    方法     |          说明          | 幂等性 |
| :---------: | :--------------------: | :----: |
|   **GET**   |      **获取资源**      |        |
|  **POST**   |    传输实**体主体**    |   否   |
|   **PUT**   |        传输文件        |        |
|  **HEAD**   |    获得报文**首部**    |        |
| **DELETE**  |        删除文件        |        |
| **OPTIONS** |     询问支持的方法     |        |
|  **TRACE**  |        追踪路径        |        |
| **CONNECT** | 要求用隧道协议连接代理 |        |

GET和POST区别：

- **GET是从服务器上获取数据，POST是向服务器传送数据**。 
- GET是把**参数**数据队列加到提交表单的ACTION属性所指的**URL中**，值和表单内各个字段一一对应，在URL中可以看到。POST是通过HTTP POST机制，将表单内各个字段与其内容放置在HTML HEADER内一起传送到ACTION属性所指的URL地址。用户看不到这个过程。 **因为GET设计成传输小数据，而且最好是不修改服务器的数据，所以浏览器一般都在地址栏里面可以看到，但POST一般都用来传递大数据，或比较隐私的数据，所以在地址栏看不到**，能不能看到不是协议规定，是浏览器规定的。**GET只支持ASCII，POST支持Unicode编码**
- 对于GET方式，服务器端用**Request.QueryString**获取变量的值，对于POST方式，服务器用**Request.Form**获取提交的数据。
- **GET传送的数据量较小，不能大于2KB。POST传送的数据量较大，一般被默认为不受限制**。只不过要修改form里面的那个type参数
- **GET安全性非常低，POST安全性较高**。 如果没有加密，他们安全级别

#### 23.HTTP如何保存用户状态

1. **基于Session实现的会话保持**
    在会话开始时，服务器将会话状态保存起来（本机内存或数据库中），然后分配一个**会话标识**（SessionId）给客户端，这个会话标识一般保存在**客户端Cookie**中，以后每次浏览器发送http请求都会带上Cookie中的SessionId到服务器，服务器拿到会话标识就可以把之前存储在服务器端的状态信息与会话联系起来，实现会话保持（如果**遇到浏览器禁用Cookie的情况，则可以通过url重写的方式将会话标识放在url的参数里**，也可实现会话保持）
2. **基于Cookie实现的会话保持**
    基于Cookie实现会话保持与上述基于Session实现会话保持的最主要区别是**前者完全将会话状态信息存储在浏览器Cookie中**，这样一来每次浏览器发送HTTP请求的时候都会带上状态信息，因此也就可以实现状态保持。

#### 24.HTTPS对称加密和非对称加密

对称加密：**加密密钥与解密密钥是相同的密码体制**

非对称加密：**加密密钥 PK**（public key，即公钥）是向公众**公开**的，而**解密密钥 SK**（secret key，即私钥或秘钥）则是需要**保密**的。加密算法 E 和解密算法 D 也都是**公开**的。虽然私钥 SK 是由公钥 PK 决定的，但却**不能**根据 PK 计算出 SK。 

#### 25.为什么TCP建立连接的时候少一次握手？

TCP建立连接的三次握手其实是四次握手的优化版，将服务器端对客户端的连接响应和自己的建立连接请求合并在一起进行握手。在建立连接的时候，不存在像断开连接的时候可能被动断开连接方的数据还没发送完的情况，所以中间两次握手可以合并起来。

#### 26.Http3.0

为了解决Http2.0多路复用底层的TCP协议的队头阻塞带来的问题，搞了一个**基于 UDP 协议的“QUIC”协议**，让HTTP跑在QUIC上而不是TCP上。

- 实现了类似TCP的流量控制、传输可靠性的功能。**0RTT 建连可以说是 QUIC 相比 HTTP2 最大的性能优势**。
- 集成了TLS加密功能。
- 多路复用，彻底解决TCP中队头阻塞的问题

#### 27.Http的Post和Put的区别

post不是幂等的

**put:**client对一个URI发送一个Entity，服务器在这个URI下如果已经又了一个Entity，那么此刻服务器应该替换成client重新提交的，也由此保证了PUT的幂等性。如果服务器之前没有Entity ，那么服务器就应该将client提交的放在这个URI上。 如果用PUT来达到更改资源，需要client提交资源全部信息，如果只有部分信息，不应该使用PUT（因为**服务器使用client提交的对象整体替换服务器的资源**）。

POST主要**作用在一个集合资源之上的**（url），而**PUT主要作用在一个具体资源之上的**（url/xxx），通俗一下讲就是，如URL可以在客户端确定，那么可使用PUT，否则用POST。

#### 28.Http2.0具体怎么实现，为什么要二进制分帧，有哪些好处，共享连接能同时发送多少个文件？

##### http2.0实现

1. 二进制分帧。
2. 多路复用共享连接。基于二进制分帧，HTTP 2.0可以在共享TCP连接的基础上，同时发送请求和响应。**HTTP消息被分解为独立的帧，而不破坏消息本身的语义，交错发送出去，最后在另一端根据流ID和首部将它们重新组合起来**。 
3. 请求优先级。
4. 服务端推送。推送，缓存，提高响应速度。
5. 首部压缩。在客户端和服务端之间使用“首部表”来跟踪和存储之前发送的键-值对。不需要每次通信都需要再携带首部。压缩算法使用HPACK。

##### 二进制分帧的好处

是建立http2.0协议的基础，可以使请求和响应信息划分为更小的帧结构，更方便的进行传输。也是多路复用共享TCP连接的基础，才能在一次连接将多个请求和响应的信息传输，通过给无序的帧标号，可以双方接收后再重新整理。

#### 29.Http的重定向机制

-  **301 Moved Permanently** ：**永久性**重定向。
-  **302 Found** ：**临时性**重定向。
-  **303 See Other** ：和 302 有着相同的功能，但是 303 明确要求客户端应该采用 **GET 方法**获取资源。
-  **304 Not Modified** ：如果**请求报文**首部包含**一些条件**，例如：**If-Match，If-Modified-Since，If-None-Match，If-Range，If-Unmodified-Since**，如果**不满足**条件，则服务器会返回 **304 状态码**。（其实这与重定向**没有**关系）。
-  **307 Temporary Redirect** ：临时重定向，与 302 的含义类似，但是 307 要求浏览器**不会**把重定向请求的 POST 方法改成 GET 方法。

#### 30.TCP的粘包拆包

tcp是以**流动的方式传输数据**，传输的最小单位为一个报文段（segment）。tcp Header中有个Options标识位，常见的标识为mss(Maximum Segment Size)指的是，**连接层每次传输的数据有个最大限制MTU**(Maximum Transmission Unit)，一般是1500比特，超过这个量要分成多个报文段，mss则是这个最大限制减去TCP的header，光是要传输的数据的大小，一般为1460比特。换算成字节，也就是180多字节。

tcp为提高性能，**发送端会将需要发送的数据发送到缓冲区，等待缓冲区满了之后，再将缓冲中的数据发送到接收方。同理，接收方也有缓冲区这样的机制，来接收数据。**

发生TCP粘包、拆包主要是由于下面一些原因：

1. 应用程序写入的数据大于套接字缓冲区大小，这将会发生拆包。
2. 应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发生粘包。
3. 进行mss（最大报文长度）大小的TCP分段，当TCP报文长度-TCP头部长度>mss的时候将发生拆包。
4. 接收方法不及时读取套接字缓冲区数据，这将发生粘包。

既然知道了**tcp是无界的数据流**，且协议本身无法避免粘包，拆包的发生，那我们只能在**应用层**数据协议上，加以控制。通常在制定传输数据时，可以使用如下方法：

1. 使用带消息头的协议、**消息头存储消息开始标识及消息长度信息**，服务端获取消息头的时候解析出消息长度，然后向后读取该长度的内容。
2. 设置**定长消息**，服务端每次读取既定长度的内容作为一条完整消息。
3. 设置**消息边界**，服务端从网络流中按消息编辑分离出消息内容。

#### 31.TCP和UDP区别

1. TCP面向连接，UDP无连接

2. TCP提供可靠的服务，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达。

    UDP尽最大努力交付，即不保证可靠交付。

3. TCP传输效率相对较低。

    UDP传输效率高，适用于对高速传输和实时性有较高的通信或广播通信。

4. TCP连接只能是点到点、一对一的。

    UDP支持一对一，一对多，多对一和多对多的交互通信。

5. UDP头部更小，传输开销更小，8字节码，TCP20字节。

#### 32.Tcp报文结构

 TCP 报文段首部的**前 20** 个字节是**固定**的，后面有 4N 字节是根据需要而增加的选项 (N 是整数)。因此 TCP 首部的最小长度是 **20 字节**。

- **==源端口和目的端口==**：各占 **2 字节**。端口是运输层与应用层的服务接口。运输层的复用和分用功能都要通过端口才能实现。 
- **==序号 seq==** ：占 **4 字节**。TCP 连接中传送的数据流中的**每一个字节**都编上一个**序号**。序号字段的值则指的是**本报文段**所发送的数据的**第一个字节**的序号。 
- **==确认号 ack==**：占 4 字节，是**期望**收到对方的**下一个报文段**的数据的**第一个字节**的序号。 

```
若确认号ack = N，则表明：到序号 N - 1 为止的所有数据都已正确收到
```

- **数据偏移**：即**首部长度**。占 4 位，它指出 TCP 报文段的**数据起始处**距离 TCP 报文段的起始处有多远。“数据偏移”的单位是 32 位字（以 4 字节为计算单位）。 
- **保留**：占 6 位，保留为今后使用，但目前应置为 0。
- **紧急 URG**：当 URG = 1 时，表明紧急指针字段**有效**。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据)。 
- **==确认 ACK 标志位==**：只有当 **ACK = 1** 时**确认号字段才有效**。当 ACK = 0 时，确认号无效。 
- **推送 PSH**：接收 TCP 收到 PSH = 1 的报文段，就尽快地交付接收应用进程，而不再等到整个缓存都填满了后再向上交付。 
- **复位 RST**：当 RST = 1 时，表明 TCP 连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。 
- ==**同步 SYN 标志位**==：（**Syn**chronize Sequence Numbers）同步 **SYN = 1** 表示这是一个==**连接请求或连接接受**==报文。在**连接时**用来**同步序号**。   
- **==终止 FIN 标志位==**：用来**释放**一个连接。**FIN = 1** 表明此报文段的**发送端**的数据已**发送完毕**，并**要求释放连接**。 
- **==窗口==**：占 2 字节，用来让**对方设置**发送窗口的依据，单位为字节。窗口字段明确指出了现在**允许对方发送**的数据量，窗口值常在动态变化着。
- **校验和**：占 2 字节。检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，临时在 TCP 报文段的前面加上 12 字节的伪首部。
- **紧急指针字段**：占 16 位，指出在本报文段中紧急数据共有多少个字节（紧急数据放在本报文段数据的最前面）。 
- **选项**：长度可变。TCP 最初只规定了一种选项，即**最大报文段长度 MSS**。MSS 告诉对方 TCP：“我的缓存所能接收的报文段的数据字段的最大长度是 MSS 个字节” 。其他选项：窗口扩大选项、时间戳选项、选择确认选项。MSS (Maximum Segment Size) 是 TCP 报文段中的数据字段的最大长度。数据字段加上 TCP 首部才等于整个的 TCP 报文段。所以，MSS 是“TCP 报文段长度减去 TCP 首部长度”。
- **填充**：这是为了使整个首部长度是 **4 字节**的**整数倍**。

#### 33.TCP拥塞控制和流量控制

|                      流量控制                      |                           拥塞控制                           |
| :------------------------------------------------: | :----------------------------------------------------------: |
| 抑制发送端发送数据的速率，以使接收端**来得及接收** | **防止**过多的数据**注入到网络**中，使网络中的路由器或链路**不致过载** |
|      是点对点通信量的控制，是**端到端**的问题      | 是一个**全局性**的过程，涉及到与降低网络传输性能有关的所有因素 |
|                  使用滑动窗口实现                  |     使用拥塞窗口变量+拥塞控制算法实现，还要配合滑动窗口      |

#### 34.网络通信双方的流程

- **服务器端：**

– 申请一个**socket** (socketWatch)用来监听的

– **绑定**到一个IP地址和一个端口上

– **开启侦听**，等待接授客户端的连接

– 当有连接时创建一个用于和连接进来的客户端进行通信的**socket**(socketConnection)

– 即续监听,等侍下一个客户的连接

- **客户端：**

– 申请一个socket(socketClient)

– 连接服务器（指明IP地址和端口号）

#### 35.http断点续传的原理？

HTTP协议的**GET方法，支持只请求某个资源的某一部分**；

206 Partial Content 部分内容响应；

Range 请求的资源范围；

Content-Range 响应的资源范围；

**在连接断开重连时，客户端只请求该资源未下载的部分，而不是重新请求整个资源**，来实现断点续传。

分块请求资源实例：

Eg1：**Range: bytes=306302-** ：请求这个资源从306302个字节到末尾的部分；

Eg2：**Content-Range: bytes 306302-604047/604048**：响应中指示携带的是该资源的第306302-604047的字节，该资源共604048个字节；

**客户端通过并发的请求相同资源的不同片段，来实现对某个资源的并发分块下载**。从而达到快速下载的目的。目前流行的FlashGet和迅雷基本都是这个原理。

多线程下载的原理：

- 下载工具开启多个发出HTTP请求的线程；

- 每个http请求只请求资源文件的一部分：Content-Range: bytes 20000-40000/47000；

- 合并每个线程下载的文件。

#### 36.arp协议

地址解析协议，是一个把IP地址转换为物理地址的TCP/IP协议。

相关要素：路由表，转发，广播，ARP缓存

#### 37.转发分组的详细过程

1. 提取数据报首部中的**目的IP地址**
2. 判断目的IP地址所在的网络**是否与本路由器直接相连**。如果是，就直接交付给目的网洛：如果不是执行3
3. 检查路由器表中是否有目的IP地址的**特定主机路由**。如果有，按特定主机路由转发：如果没有，执行4
4. 逐条检查路由表。若找到匹配路由，则按照路由表进行转发：若所有路由均不匹配，则执行5
5. 若路由表中设置有默认路由，则按照默认路由表转发：否则，执行6
6. 向源主机报错。

#### 38.tcp访问一个主机如果主机端口不存在返回什么信息

##### TCP建立连接异常情况分析

1. 试图与一个**不存在**的端口建立连接（主机正常）

    这里的不存在的端口是指在服务器端没有程序监听在该端口。我们的客户端就调用connect，试图与其建立连接。

    这种情况下我们在客户端通常会收到如下异常内容：

    > [Errno 111] **Connection refused（连接拒绝）**

    当客户端的SYNC包到达服务端时，TCP协议没有找到监听的套接字，就会向客户端发送一个错误的报文，告诉客户端产生了错误。而该错误报文就是一个**包含RST的报文**。这种异常情况也很容易模拟。

2. 试图与一个**某端口建立连接但该主机已经宕机**（主机宕机）

    这也是一种比较常见的情况，当某台服务器主机宕机了，而客户端并不知道，仍然尝试去与其建立连接。这种场景也是分为2种情况的，一种是刚刚宕机，另外一种是宕机了很长时间。为什么要分这2种情况？

    这主要根ARP协议有关系，ARP会在本地缓存失效，TCP客户端就无法向目的服务端发送数据包了。

    刚刚宕机的情况，此时客户端是可以向服务端发送数据包的。但是由于服务器宕机，因此不会给客户端发送任何回复。

3. 建立连接时，服务器应用被阻塞（或者僵死）

    还有一种情况是在客户端建立连接的过程中服务端应用处于僵死状态，这种情况在实际中也会经常出现（我们假设仅仅**应用程序僵死，而内核没有僵死**）。

    服务端通过**accept接口返回一个新的套接字**，这时就可以和客户端进行数据往来了。也就是在用户层面来说，**accept返回结果说明3次握手完成了，否则accept会被阻塞**。

    accept会通过软中断陷入内核中，最终会调用tcp协议的inet_csk_accept函数，该函数会**从队列中查找是否有处于ESTABLISHED状态的套接字**。如果有则返回该套接字，否则阻塞当前进程。也就是说这里只是一个查询的过程，**并不参与三次握手的任何逻辑**。

    三次握手的本质是什么呢？实际上就是客户端与服务端一个不断交流的过程，而这个交流过程就是通过3个数据包完成的。而这个数据包的发送和处理实际上都是在**内核**中完成的。对于TCP的服务端来说，**当它收到SYNC数据包时，就会创建一个套接字的数据结构并给客户端回复ACK，再次收到客户端的ACK时会将套接字数据结构的状态转换为ESTABLISHED，并将其发送就绪队列中**。而这整个过程**跟应用程序没有关系**。

    当上面套接字加入就绪队列时，accept函数就被唤醒了，然后就可以获得新的套接字并返回。但我们回过头来看一下，**在accept返回之前，其实三次握手已经完成，也就是连接已经建立了**。

    另外一个是**如果accept没有返回，客户端是否可以发送数据？答案是可以的**。因为数据的发送和接受都是在内核态进行的。**客户端发送数据后，服务端的网卡会先接收，然后通过中断通知IP层，再上传到TCP层**。TCP层根据目的端口和地址将数据存入关联的缓冲区。如果此时应用程序有读操作（例如read或recv），那么数据会**从内核态的缓冲区拷贝到用户态的缓存**。否则，数据会一直在内核态的缓冲区中。总的来说，**TCP的客户端是否可以发送数据与服务端程序是否工作没有任何关系**。

    当然，如果是整个机器都卡死了，那就是另外一种情况了。这种情况就我们之前分析的第2种情况了。因为，由于机器完全卡死，TCP服务端无法接受任何消息，自然也无法给客户端发送任何应答报文。

#### 39.那怎么知道这个信息是什么呢

通过tcpdump 抓包抓到的一个个tcp 的pcap 包，可以通过wireshark 打开。

#### 40.网络的整个协议栈

![七层体系结构图](校招面经.assets/七层体系结构图-4137025.png)

![image-20210224112441341](校招面经.assets/image-20210224112441341.png)

#### 41.一个TCP程序的具体步骤

#### 42.网络定时器的机制

##### 采用sleep函数

sleep函数在**实现时用了SIGALRM信号机制**， 在多线程程序中处理信号是个相当麻烦的事情，应当尽量避免

原因：

1. 如果要处理多个定时任务，就要不断触发SIGALRM信号，并在信号处理函数中执行到期任务
2. **在**多线程环境下，产生的信号是传递给整个进程的，一般而言，所有线程都有机会收到这个信号，要做特殊的信号阻塞处理、考虑线程安全问题
3. SIGALRM信号**按照固定的频率生成**，由alarm或settimer函数设定定时周期T保持不变。如果定时时间周期不是T的整数倍，那么实际执行时和与其时间将会有偏差

##### 采用timerfd + epoll

timerfd是Linux为用户程序提供的一个定时器接口。这个接口基于文件描述符，**通过文件描述符的可读事件进行超时通知**，**在定时器超时的那一刻变得可读**，这样就能很方便地融入到 select/poll 框架中，用统一的方式来处理 IO 事件和超时事件。

优点：

1. 由timerfd可以方便的创建多个定时器，由epoll进行监听，实现简单

缺点：

1. 创建多个定时器时，需要占用多个timerfd
2. epoll和timerfd必须搭配使用，也就造成了添加一个定时器至少包含三个系统调用(timerfd_create()、 timerfd_settime()、epoll_ctl())，若服务端要面对大量的网络连接与大量的定时器使用，那么这对性能应该存在一定影响

##### 采用链表

- 将定时器作为链表节点管理
- 插入/删除/查找时进行遍历判断

时间复杂度上：

1. 无序链表: 插入时直接头插O(1), 删除和超时时需要遍历判断定时器情况O(n)
2. 有序链表: 采用升序链表, 插入时需要找到合适的位置, 时间复杂度是O(n), 删除和超时, 距今时间最近的定时器节点一定是在起始处, 所以事件复杂度是O(1)

##### 采用时间轮

时间轮**提前确定好时间的间隔**，在每一个槽上都是一个链表，这个链表中的时间都是一致的，不同链表上的定时时间相差槽间隔的整数倍，当指针指向当前格子时，便将所有超时时间直接处理，并且移除。

优点：

1. 将定时器散列到不同的链表上，这样每条链表上的定时器数目将会明显少于链表上的定时器数目，插入操作效率提高。

时间复杂度：

- 时间复杂度是O(1)
- 删除: O(1)
- 超时: O(1)

##### 采用时间堆

之前链表和时间轮都是以固定的频率一次检测到期的定时器，然后执行到期定时器上的回调函数，时间堆是实现定时器的另外一种思路：**将所有定时器中超时时间最小的一个定时器的超时值作为间隔**，每次调用时时间最小的定时器必然到期，然后执行定时器上的回调函数，之后再从剩余的定时器上找出超时时间最小的一个，并将这段时间作为下一个时间间隔。

采用数据结构：最小堆

时间复杂度上：

1. 最小堆保证最小的节点在顶部, 所以删除, 超时的时间复杂是O(1)
2. 因为最小堆的性质要求, 插入时间复杂度也是O(lgn)

#### 43.网络的协议栈，为什么要分层？

一灵活性好：当任何一层发生变化时，只要层间接口关系保持不变，则在这层以上或以下各层均不受影响。此外，对某一层提供的服务还可进行修改。当某层提供的服务不再需要时，甚至可以将这层取消，更容易管理。


二各层之间是独立的：在各层间标准化接口，允许不同的产品只提供各层功能的一部分，某一层不需要知道它的下一层是如何实现的，而仅仅需要知道该层通过层间的接口所提供的服务。由于每一层只实现一种相对独立的功能，所以比较容易实现！

#### 44.URL的格式

协议://用户名:密码@子域名.域名.顶级域名:端口号/目录/文件名.文件后缀?参数=值#标志

一般格式

<协议>://<主机>:<端口>/<路径>

#### 45.动态路由

路由器能够自动地建立自己的路由表，并且能够根据实际情况的变化适时地进行调整。

常见的动态路由协议有以下几个：

##### RIP

**路由信息协议**（RIP） 是内部网关协议IGP中最先得到广泛使用的协议。RIP是一种分布式的**基于距离向量**的路由选择协议，是因特网的标准协议，其最大优点就是实现简单，开销较小。

仅和相邻路由器交换信息（当前路由器所知的全部信息，即自己的路由表）。基于UDP传送数据。

##### OSPF

OSPF(Open Shortest Path First**开放式最短路径优先**）是一个内部网关协议(Interior Gateway Protocol，简称IGP），用于在单一自治系统内决策路由。

向本自己系统中的所有路由器发送信息，泛洪法，信息包含所有与本路由器相邻的路由器的状态。使用IP数据报直接传送。

##### IS-IS

IS-IS（Intermediate System-to-Intermediate System，**中间系统到中间系统**）路由协议最初是ISO为CLNP（Connection Less Network Protocol，无连接网络协议）设计的一种动态路由协议。

##### BGP

**边界网关协议**（BGP）是**运行于 TCP 上的一种自治系统的路由协议**。 BGP 是唯一一个用来处理像因特网大小的网络的协议，也是唯一能够妥善处理好不相关路由域间的多路连接的协议。力求寻找一条能够到达目的网络且**比较好的路由**（不能兜圈子），而**并非**要寻找一条最佳路由。 BGP发言人之间建立TCP连接交换路由信息。

#### 46.HTTP的报文格式

##### 请求

###### 请求行

由请求方法字段、URL字段和HTTP协议版本字段3个字段组成，它们用空格分隔。比如 GET /data/info.html HTTP/1.1

###### 请求头部

HTTP客户程序向服务器发送请求的时候**必须指明请求类型**(一般是GET或者 POST)。大多数请求头并不是必需的，但Content-Length除外。**对于POST请求来说 Content-Length必须出现**。

###### 空行

通过一个空行，告诉服务器请求头部到此为止。

###### 请求数据

若方法字段是GET，则此项为空，没有数据；若方法字段是POST,则通常来说此处放置的就是要提交的数据

![请求报文格式](../Untitled.assets/20160921092902554.png)

##### 响应

由三部分组成：响应行、响应头、响应体

###### 响应行

一般由**协议版本、状态码及其描述**组成 比如 HTTP/1.1 200 OK

###### 响应头

用于描述服务器的基本信息，以及数据的描述，服务器通过这些数据的描述信息，可以通知客户端如何处理等一会儿它回送的数据。

设置HTTP响应头往往和状态码结合起来。

###### 响应体

就是响应的消息体，如果是纯数据就是返回纯数据，如果请求的是HTML页面，那么返回的就是HTML代码，如果是JS就是JS代码，如此之类。

![http响应报文格式](../Untitled.assets/20160921092902557.jpg)

#### 47.Time_Wait？有什么方法可以避免Time_Wait?TIME_WAIT 是主动断开连接的一方还是被动断开的一方？

可以一看https://www.cnblogs.com/albert32/p/13414204.html

主动断开连接放进行TIME_WAIT取2MSL(报文最大生存时间)主要是保证主动断开方对于被动断开方的FIN的响应能够被接收到，正常关断，如果未正常响应，则服务端会重新发送FIN报文，就是为了解决这个问题。同时等待一段时间是为了让本次连接产生的报文从网络中都消失，下一个连接的时候不会出现旧的报文。

##### Time_Wait调优

###### **net.ipv4.tcp_timestamps**

**两个4字节的时间戳字段**，其中第一个4字节字段用来保存**发送该数据包的时间**，第二个4字节字段用来保存**最近一次接收对方发送到数据的时间**。

###### **net.ipv4.tcp_tw_reuse**

出现TIME_WAIT状态的连接，一定出现在主动关闭连接的一方。所以，当**主动关闭连接的一方，再次向对方发起连接请求的时候**（例如，客户端关闭连接，客户端再次连接服务端，此时可以复用了；负载均衡服务器，主动关闭后端的连接，当有新的HTTP请求，负载均衡服务器再次连接后端服务器，此时也可以复用），**可以复用TIME_WAIT状态的连接**。

通过字面解释以及例子说明，可以看到，tcp_tw_reuse应用的场景：某一方，需要不断的通过“**短连接**“连接其他服务器，总是**自己先关闭连接**(TIME_WAIT在自己这方)，**关闭后又不断的重新连接对方**。

> **当连接被复用了之后，延迟或者重发的数据包到达，新的连接怎么判断，到达的数据是属于复用后的连接，还是复用前的连接呢？**
>
> 那就需要依赖前面提到的两个时间字段了。复用连接后，这条连接的时间被更新为当前的时间，当延迟的数据达到，延迟数据的时间是小于新连接的时间，所以，内核可以通过时间判断出，延迟的数据可以安全的丢弃掉了。

这个配置，依赖于连接双方，同时对timestamps的支持。同时，这个配置，仅仅影响做为客户端的角色，连接服务端[connect(dest_ip, dest_port)]时复用TIME_WAIT的socket。

###### **net.ipv4.tcp_tw_recycle**

当开启了这个配置后，**内核会快速的回收处于TIME_WAIT状态的socket连接**。多快？**不再是2MSL，而是一个RTO**（retransmission timeout，**数据包重传的timeout时间**）的时间，这个时间根据RTT动态计算出来，但是远小于2MSL。

有了这个配置，还是需要保障丢失重传或者延迟的数据包，不会被新的连接(注意，这里不再是复用了，而是之前处于TIME_WAIT状态的连接已经被destroy掉了，新的连接，刚好是和某一个被destroy掉的连接使用了相同的五元组而已)所错误的接收。在启用该配置，当一个**socket连接进入TIME_WAIT状态后**，**内核里会记录包括该socket连接对应的五元组中的对方IP等在内的一些统计数据**，当然也包括从该对方IP所接收到的最近的一次数据包时间。**当有新的数据包到达，只要时间晚于内核记录的这个时间，数据包都会被统统的丢掉**。

这个配置，依赖于连接双方对timestamps的支持。同时，这个配置，主要影响到了inbound的连接（对outbound的连接也有影响，但是不是复用），即**做为服务端角色，客户端连进来，服务端主动关闭了连接，TIME_WAIT状态的socket处于服务端，服务端快速的回收该状态的连接。**

由此，如果客户端处于NAT的网络(多个客户端，同一个IP出口的网络环境)，如果配置了tw_recycle，就可能在一个RTO的时间内，只能有一个客户端和自己连接成功(不同的客户端发包的时间不一致，造成服务端直接把数据包丢弃掉)。

#### 48.Time_wait，Close_wait分别出现在哪个阶段，会造成什么影响？ 

主动断开方向被动断开方发送FIN报文，进入FIN-WAIT-1状态，被动断开方收到后回复ACK（主动方收到ACK进入FIN-WAIT-2状态），同时通知上层应用，并进入close_wait阶段。等待上层应用数据发送完成本次连接的数据后进行关闭，结束Close_wait,发送FIN报文，进入last_ack阶段。主动断开方在收到FIN报文后，发送ACK并进入Time_Wait阶段，等待2MSL后close。

一条Socket处于TIME_WAIT状态，它也是一条“存在“的socket，内核里也需要有保持它的数据：

1) 内核里有保存所有连接的一个hash table，这个hash table里面既包含TIME_WAIT状态的连接，也包含其他状态的连接。主要用于有新的数据到来的时候，从这个hash table里快速找到这条连接。

2) 还有一个hash table用来保存所有的bound ports，主要用于可以快速的找到一个可用的端口或者随机端口

由于内核需要保存这些数据，必然，会占用一定的内存。

同时也会占用这个socket，一共65536个端口。新来的连接无法建立连接。

#### 49.http和tcp的区别，什么时候用http，什么时候用tcp

http再建立TCP连接之后，需要再升级。同时是采用请求-响应的方式进行数据传送，http1.0以下是短连接，1.1以上是长连接，半双工，而TCP可以全双工的进行双向传输数据。

- 用HTTP的情况：双方不需要时刻保持连接在线，比如客户端资源的获取、文件上传等。
- 用Socket（TCP）的情况：大部分即时通讯应用(QQ)、聊天室、苹果APNs等

#### 100.一个网页的请求过程







### 3.操作系统

#### 1.IO多路复用，epoll与select，poll对比，实现和区别

##### 1.IO模型

###### 同步和异步

针对比如接口调用，服务调用，API类库调用等

**同步**：用者必须要等待这个接口的磁盘读写或者网络通信的操作执行完毕了，调用者才能返回

**异步**：调用者调用接口之后，直接就返回了，他去干别的事儿了，也不管那个接口的磁盘读写或者是网络通信是否成功，然后这个接口后续如果干完了自己的任务，比如写完了文件或者是什么的，会反过来通知调用者，之前你的那个调用成功了。可以通过一些内部通信机制来通知，也可以通过回调函数来通知。

###### 阻塞和非阻塞

针对底层IO操作

**阻塞**：比如现在我们的程序想要通过网络读取数据，如果是阻塞IO模式，一旦发起请求到操作系统内核去从网络中读取数据，就会阻塞在那里，必须要等待网络中的数据到达了之后，才能从网络读取数据到内核，再从内核返回给程序。

**非阻塞**：程序发送请求给内核要从网络读取数据，但是此时网络中的数据还没到，此时不会阻塞住，内核会返回一个异常消息给程序，程序可以干点别的，然后不断去**轮询**去访问内核，看请求的数据是否读取到了。

###### BIO，NIO和AIO

**BIO**：主要就是**同步阻塞**IO模型，代码里调用IO相关接口，发起IO操作之后，程序就会同步等待，**这个同步指的是程序调用IO API接口的层面而言**。而IO API在底层的IO操作是**基于阻塞IO**来的，向操作系统内核发起IO请求，系统内核会等待数据就位之后，才会执行IO操作，执行完毕了才会返回。

**NIO**是**同步非阻塞**，也就是说如果你调用NIO接口去执行IO操作，其实还是同步等待的，但是在底层的IO操作上 ，会对系统内核发起非阻塞IO请求，以非阻塞的形式来执行IO。也就是说，**如果底层数据没到位，那么内核返回异常信息，不会阻塞住，但是NIO接口内部会采用非阻塞方式过一会儿再次调用内核发起IO请求，直到成功为止。**但是之所以说是同步非阻塞，这里的**“同步”指的就是因为在你的代码调用NIO接口层面是同步的**，你还是要同步**等待底层IO操作真正完成了才可以返回**，只不过**在执行底层IO的时候采用了非阻塞的方式**来执行罢了。

###### **NIO网络通信与IO多路复用模型**

如果基于NIO进行网络通信，采取的就是多路复用的IO模型，这个多路复用IO模型针对的是网络通信中的IO场景来说的。简单来说，就是在基于Socket进行网络通信的时候，如果有多个客户端跟你的服务端建立了Socket连接，那你就需要维护多个Socket连接。

而所谓的多路复用IO模型，就是说你的代码直接通过一个select函数调用，直接会进入一个同步等待的状态。

这也是为什么说**NIO一定是“同步”的，因为你必须在这里同步等待某个Socket连接有请求到来**。

接着你就要同步等着select函数去对底层的多个 Socket 连接进行轮询，不断的查看各个 Socket 连接谁有请求到达，就可以让select函数返回，交给我们的程序来处理。

**select函数在底层会通过非阻塞的方式轮询各个Socket**，任何一个Socket如果没有数据到达，那么非阻塞的特性会立即返回一个信息。

然后select函数可以轮询下一个Socket，**不会阻塞在某个Socket上**，所以底层是基于这种非阻塞的模式来“监视”各个Socket谁有数据到达的。

这就是所谓的“同步非阻塞”，但是因为操作系统把上述工作都封装在一个select函数调用里了，可以对多路Socket连接同时进行监视，所以就把这种模型称之为“IO多路复用”模型。

通过这种IO多路复用的模型，就可以用一个线程，调用一个select函数，然后监视大量的客户端连接了。

###### **AIO**

AIO，也叫做NIO 2.0，他就支持异步IO模型了。我们先说一下异步IO模型是什么意思。

简单来说，就是你的程序可以基于AIO API发起一个请求，比如说接收网络数据，AIO API底层会基于异步IO模型来调用操作系统内核。此时不需要去管这个IO是否成功了，AIO接口会直接返回，你的程序也会直接返回。

因为BIO、NIO都是同步的，你发起IO请求，都必须同步等待IO操作完成。但是这里你发起一个IO请求，直接AIO接口就返回了，你就可以干别的事儿了，纯异步的方式。不过你**需要提供一个回调函数给AIO接口**，一旦底层系统内核完成了具体的IO请求，比如网络读写之类的，就会回调你提供的回调函数。

###### **用户空间和内核空间**

用户空间是**常规进程**所在区域，是**非特权**区域：比如，在该区域执行的代码就**不能直接访问硬件设备**。 

内核空间是**操作系统**所在区域。内核代码有特别的权力：它能与设备控制器通讯，控制着用户区域进程的运行状态，等等。最重要的是，**所有 I/O 都直接（如这里所述）通过内核空间**。 

**当进程请求 I/O 操作的时候，它执行一个系统调用（有时称为陷阱）将控制权移交给内核**。 C/C++程序员所熟知的底层函数 open( )、read( )、write( )和 close( )要做的无非就是建立和执行适当的系统调用。当内核以这种方式被调用，它随即采取任何必要步骤，**找到进程所需数据，并把数据传送到用户空间内的指定缓冲区**。内核试图对数据进行高速缓存或预读取，因此进程所需数据可能已经在内核空间里了。如果是这样，该数据只需简单地拷贝出来即可。如果数据不在内核空间，则进程被挂起，内核着手把数据读进内存。 

**把数据从内核空间拷贝到用户空间似乎有些多余。为什么不直接 让磁盘控制器把数据送到用户空间的缓冲区呢？**这样做有几个问题。首先，硬件通常不能直接访问用户空间 。其次，像磁盘这样基于块存储的硬件设备操作的是固定大小的数据块，而用户进程请求的可能是任意大小的或非对齐的数据块。在数据往来于用户空间与存储设备的过程中，**内核负责数据的分解、再组合工作，因此充当着中间人的角色**。

**==I/O多路复用发生在read()操作之前，也就是传输fd==**。

##### select，poll，epoll对比

###### select

- select**能监控的描述符个数**由内核中的FD_SETSIZE限制，仅为**1024**，这也是select**最大的缺点**，因为现在的服务器并发量远远不止1024。即使能重新编译内核改变FD_SETSIZE的值，但这并不能提高select的性能。
- 每次调用select都会**线性扫描所有描述符的状态**，在select结束后，用户也要线性扫描fd_set数组才知道哪些描述符准备就绪，等于说**每次调用复杂度都是O（n）的**，在并发量大的情况下，每次扫描都是相当耗时的，很有可能有未处理的连接等待超时。
- 每次调用select都要**在用户空间和内核空间里进行内存复制fd描述符等信息**。

###### poll

- poll使用**pollfd结构**来存储fd，**突破了select中描述符数目的限制**。采用**链表**的方式替换原有fd_set数据结构，poll使用pollfd的指针，pollfd结构包含了要监视的event和发生的evevt，不再使用select传值的方法。更方便，而使其没有连接数的限制。
- 与select的后两点类似，poll**仍然需要将pollfd数组拷贝到内核空间**，之后依次扫描fd的状态，整体复杂度依然是**O（n）**的，在并发量大的情况下服务器性能会快速下降。

###### epoll

- epoll维护的描述符数目**不受到限制**，而且**性能不会随着描述符数目的增加而下降**。
- 服务器的特点是经常维护着大量连接，但其中某一时刻读写的操作符数量却不多。epoll先通过epoll_ctl**注册一个描述符到内核中**，并一直维护着而不像poll每次操作都将所有要监控的描述符传递给内核；在**描述符读写就绪时，通过回调函数将自己加入就绪队列中**，之后**epoll_wait返回该就绪队列**。也就是说，epoll基本不做无用的操作，**时间复杂度仅与活跃的客户端数有关**，而不会随着描述符数目的增加而下降。
- epoll在传递内核与用户空间的消息时使用了**内存共享，而不是内存拷贝**，这也使得epoll的效率比poll和select更高。

###### 总结

在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点：
1、表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟**epoll的通知机制需要很多函数回调**。
2、select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善。



#### 2.内核态用户态，使用场景，切换方式

##### 内核态用户态

根据**进程访问资源的特点**，我们可以把**进程**在系统上的运行分为**两个级别**：

1. **用户态(user mode)** ：用户态运行的进程或可以直接读取**用户程序**的数据。
2. **系统态(kernel mode)**：可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。

**为什么需要两个？**

在 CPU 的所有指令中，有些指令是非常危险的，如果使用不当，将会造成系统崩溃等后果。

为了避免这种情况发生，CPU 将指令划分为**特权级(内核态)指令**和**非特权级(用户态)指令。**

**对于那些危险的指令只允许内核及其相关模块调用，对于那些不会造成危险的指令，就允许用户应用程序调用。**

* 内核态(核心态,特权态): **内核态是操作系统内核运行的模式。**
    内核态控制**计算机的硬件资源，如硬件设备，文件系统等等**，并为上层应用程序提供执行环境。

* 用户态: **用户态是用户应用程序运行的状态。**
    应用程序必须依托于内核态运行,因此用户态的态的操作权限比内核态是要低的，
    如**磁盘，文件**等，访问操作都是受限的。
* 系统调用: 系统调用是操作系统为应用程序提供能够访问到内核态的资源的接口。

我们运行的**程序基本都是运行在用户态**，如果我们调用操作系统提供的系统态级别的子功能咋办呢？那就需要**系统调用**了！

也就是说在我们运行的用户程序中，凡是**与系统态级别的资源有关的操作**（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

##### 切换方式

* **系统调用**: 系统调用是用户态**主动要求**切换到内核态的一种方式，
    用户应用程序通过操作系统调用内核为上层应用程序开放的接口来执行程序。
* **异常**: 当 CPU 在执行用户态的应用程序时，**发生了某些不可知的异常**。
    于是当前用户态的应用进程切换到处理此异常的内核的程序中去。
* **硬件设备的中断**: 当硬件设备完成用户请求后，会向 CPU 发出相应的中断信号，
    这时 CPU 会暂停执行下一条即将要执行的指令，转而去执行与中断信号对应的应用程序，
    如果先前执行的指令是用户态下程序的指令，那么这个转换过程也是用户态到内核态的转换。

Linux 的系统调用主要有以下这些：

|     Task     | Commands                               |
| :----------: | -------------------------------------- |
| **进程控制** | **fork**(); **exit**(); **wait**();    |
| **进程通信** | **pipe**(); **shmget**(); mmap();      |
| **文件操作** | **open**(); **read**(); **write**();   |
| **设备操作** | ioctl(); **read**(); write();          |
| **信息维护** | **getpid**(); alarm(); **sleep**();    |
|   **安全**   | **chmod**(); **umask**(); **chown**(); |

#### 3.进程，线程，协程

链接：https://www.cnblogs.com/Survivalist/p/11527949.html

**进程**，直观点说，保存在硬盘上的程序运行以后，会在内存空间里形成一个独立的内存体，这个内存体**有自己独立的地址空间，有自己的堆**，上级挂靠单位是**操作系统**。**操作系统会以进程为单位，分配系统资源（CPU时间片、内存等资源），进程是资源分配的最小单位**。

**线程**，有时被称为轻量级进程(Lightweight Process，LWP），**是操作系统调度（CPU调度）执行的最小单位**。

##### 进程和线程的区别

1. 线程是**程序执行**的最小单位，而进程是操作系统**分配资源**的最小单位；
2. 一个进程由一个或多个线程组成，线程是一个进程中代码的不同执行路线；
3. 进程之间相互独立，但同一进程下的各个线程之间共**享程序的内存空间**(包括代码段、数据集、堆等)及一些进程级的资源(如打开文件和信号)，**某进程内的线程在其它进程不可见**；
4. 调度和切换：线程上下文切换比进程上下文切换要快得多。

##### 任务调度

大部分操作系统(如Windows、Linux)的任务调度是采用**时间片轮转的抢占式调度**方式。

在一个进程中，当一个线程任务执行几毫秒后，会由操作系统的**内核进行调度**，通过硬件的计数器中断处理器，让该线程强制暂停并将该线程的寄存器放入内存中，通过查看线程列表决定接下来执行哪一个线程，并从内存中恢复该线程的寄存器，最后恢复该线程的执行，从而去执行下一个任务。上述过程中，任务执行的那一小段时间叫做时间片，任务正在执行时的状态叫运行状态，被暂停的线程任务状态叫做就绪状态，意为等待下一个属于它的时间片的到来。

##### 多线程与多核

现在的电脑一般是双核四线程、四核八线程，是采用**超线程技术**将一个物理处理核心模拟成两个逻辑处理核心，对应两个内核线程，所以在操作系统中看到的CPU数量是实际物理CPU数量的两倍。

程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口——**轻量级进程**（Lightweight Process，LWP），轻量级进程就是我们通常意义上所讲的线程，也被叫做**用户线程**。由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。

用户线程与内核线程的对应关系有三种模型：一对一模型、多对一模型、多对多模型。

##### 一对一模型

一个用户线程就唯一地对应一个内核线程，一个用户线程就唯一地映射到一个物理CPU的内核线程，线程之间的并发是真正的并发。

###### 优点

一对一模型使用户线程具有与内核线程一样的优点，**一个线程因某种原因阻塞时其他线程的执行不受影响**；此处，一对一模型也可以让多线程程序在多处理器的系统上有更好的表现。

###### 缺点

1. 许多操作系统限制了内核线程的数量，因此一对一模型会使用户线程的数量受到限制；
2. 许多操作系统内核线程调度时，上下文切换的开销较大，导致用户线程的执行效率下降。

##### 多对一模型

将多个用户线程映射到一个内核线程上，线程之间的切换由用户态的代码来进行，系统内核感受不到线程的实现方式。用户线程的建立、同步、销毁等都在用户态中完成，不需要内核的介入。

###### 优点

多对一模型的线程上下文切换速度要快许多；此外，多对一模型对用户线程的数量几乎无限制。

###### 缺点

1. 如果其中一个用户线程阻塞，那么其它所有线程都将无法执行，因为此时内核线程也随之阻塞了；
2. 在多处理器系统上，处理器数量的增加对多对一模型的线程性能不会有明显的增加，因为所有的用户线程都映射到一个处理器上了。

##### 多对多模型

将多个用户线程映射到多个内核线程上。由线程库负责在可用的可调度实体上调度用户线程，这使得线程的上下文切换非常快，因为它避免了系统调用。但是增加了复杂性和优先级倒置的可能性，以及在用户态调度程序和内核调度程序之间没有广泛（且高昂）协调的次优调度。

多对多模型的优点有：

1. 一个用户线程的阻塞不会导致所有线程的阻塞，因为此时还有别的内核线程被调度来执行；
2. 多对多模型对用户线程的数量没有限制；
3. 在多处理器的操作系统中，多对多模型的线程也能得到一定的性能提升，但提升的幅度不如一对一模型的高。

##### 线程的生命周期

当线程的数量小于处理器的数量时，线程的并发是真正的并发，不同的线程运行在不同的处理器上。但当线程的数量大于处理器的数量时，线程的并发会受到一些阻碍，此时并不是真正的并发，因为此时至少有一个处理器会运行多个线程。

在单个处理器运行多个线程时，并发是一种模拟出来的状态。操作系统采用时间片轮转的方式轮流执行每一个线程。线程是程序执行的最小单位，也是任务执行的最小单位。

进程在运行过程有三种状态：就绪、运行、阻塞，创建和退出状态描述的是进程的创建过程和退出过程。

- 创建：进程正在创建，还不能运行。操作系统在创建进程时要进行的工作包括**分配和建立进程控制块表项、建立资源表格并分配资源、加载程序并建立地址空间**；
- 就绪：**时间片已用完，此线程被强制暂停，等待**下一个属于它的时间片到来；
- 运行：此线程正在执行，**正在占用时间片**；
- 阻塞：也叫等待状态，**等待某一事件(如IO或另一个线程)执行完**；
- 退出：进程已结束，所以也称结束状态，**释放操作系统分配的资源**。

**线程**：

- 创建：一个新的线程被创建，等待该线程被调用执行；
- 就绪：**时间片已用完**，此线程被强制暂停，等待下一个属于它的时间片到来；
- 运行：此线程正在执行，正在占用时间片；
- 阻塞：也叫等待状态，等待某一事件(如IO或另一个线程)执行完；
- 退出：**一个线程完成任务或者其他终止条件发生**，该线程终止进入退出状态，退出状态释放该线程所分配的资源。

##### 协程

Coroutines，是一种基于线程之上，但又比线程更加轻量级的存在，由程序员自己写程序来管理的轻量级线程叫做『**用户空间线程**』，具有**对内核来说不可见**的特性。

###### 协程的目的

在传统的J2EE系统中都是基于每个请求占用一个线程去完成完整的业务逻辑（包括事务）。所以系统的吞吐能力取决于每个线程的操作耗时。如果遇到很耗时的I/O行为，则整个系统的吞吐立刻下降，因为这个时候**线程一直处于阻塞状态，如果线程很多的时候，会存在很多线程处于空闲状态（等待该线程执行完才能执行）**，造成了资源应用不彻底。

而协程的目的就是**当出现长时间的I/O操作时，通过让出目前的协程调度，执行下一个任务的方式，来消除ContextSwitch上的开销**。

###### 协程的特点

1. 线程的切换由操作系统负责调度，协程由**用户自己进行调度**，因此**减少了上下文切换**，提高了效率。
2. 线程的默认Stack大小是1M，而协程更轻量，接近1K。因此可以在相同的内存中开启更多的协程。
3. 由于在同一个线程上，因此可以**避免竞争关系而使用锁**。
4. 适用于被阻塞的，且需要**大量并发**的场景。但**不适用于大量计算的多线程**，遇到此种情况，更好实用线程去解决。

###### 协程的原理

当**出现IO阻塞**的时候，由协程的调度器进行**调度**，通过将数据流立刻yield掉（**主动让出**），并且**记录当前栈上的数据，阻塞完后立刻再通过线程恢复栈**，并把阻塞的结果放到这个线程上去跑，这样看上去好像跟写同步代码没有任何差别，这整个流程可以称为coroutine，而跑在由`coroutine`负责调度的线程称为`Fiber`。比如Golang里的 go关键字其实就是负责开启一个`Fiber`，让`func`逻辑跑在上面。

由于协程的暂停完全由程序控制，发生在**用户态**上；而线程的阻塞状态是由操作系统内核来进行切换，发生在内核态上。因此，协程的开销远远小于线程的开销，也就没有了ContextSwitch上的开销。



#### 4.进程通信方法

##### 1.管道

**半双工**的，具有固定的读端和写端。

分为命名管道FIFO，无名管道Pipe，除了建立、打开、删除的方式不同外，这两种管道几乎是一样的。他们都是通过内核缓冲区实现数据传输。

- pipe用于**相关进程**之间的通信，例如父进程和子进程，它通过pipe()系统调用来创建并打开，当最后一个使用它的进程关闭对他的引用时，pipe将**自动撤销**。
- FIFO即命名管道，**在磁盘上有对应的节点，但没有数据块**——换言之，只是**拥有一个名字和相应的访问权限**，通过mknode()系统调用或者mkfifo()函数来建立的。一旦建立，**任何进程都可以通过文件名将其打开和进行读写，而不局限于父子进程**，当然前提是进程对FIFO有适当的访问权。**当不再被进程使用时，FIFO在内存中释放，但磁盘节点仍然存在**。
- 将另一个程序当做一个新的进程在当前程序进程中启动，则它算是**当前程序的子进程**，这种方式我们成为**高级管道方式**。

管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据：管道一端的进程顺序地将进程数据写入缓冲区，另一端的进程则顺序地读取数据，该缓冲区可以看做一个循环队列，读和写的位置都是自动增加的，一个数据只能被读一次，读出以后再缓冲区都不复存在了。当缓冲区读空或者写满时，有一定的规则控制相应的读进程或写进程是否进入等待队列，当空的缓冲区有新数据写入或慢的缓冲区有数据读出时，就**唤醒等待队列中的进程继续读写**。

##### 2.消息队列

消息队列，就是**一系列保存在内核中消息的列表**。用户进程可以向消息队列添加消息，也可以向消息队列读取消息。消息队列与管道通信相比，其**优势**是**对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息**。可以把消息看做一个记录，**具有特定的格式以及特定的优先级**。

进程间通过消息队列通信，主要是：创建或打开消息队列，添加消息，读取消息和控制消息队列。

##### 3.共享内存

共享内存**允许两个或多个进程共享一个给定的存储区**，这一段存储区可以被两个或两个以上的进程**映射至自身的地址空间中**，一个进程写入共享内存的信息，可以被其他使用这个共享内存的进程，通过一个简单的内存读取读出，从而实现了进程间的通信。

采用共享内存进行通信的一个主要好处是**效率高**，因为进程可以直接读写内存，而**不需要任何数据的拷贝**，对于像管道和消息队里等通信方式，则需要再内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次：一次从输入文件到共享内存区，另一次从共享内存到输出文件。

一般而言，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时在重新建立共享内存区域；而是**保持共享区域，直到通信完毕为止**，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是**在解除映射时才写回文件**，因此，采用共享内存的通信方式效率非常高。

共享内存有两种实现方式：1、内存映射 2、共享内存机制

##### 4.信号量

信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个**计数器**。信号量用于实现进程间的**互斥与同步**，而**不是用于存储进程间通信数据**。可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。

信号量**用于进程间同步，若要在进程间传递数据需要结合共享内存。**

信号量基于操作系统的 PV 操作，**程序对信号量的操作都是原子操作**。

每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。

支持信号量组。

##### 5.信号

用于通知接收进程某个事件已经发生。

##### 6.套接字( socket )  

与其他通信机制不同的是，它**可用于不同机器间的进程通信**。通过运行一个进程监听某个端口进行通信。



#### 5.什么是**零拷贝**？

链接：https://www.cnblogs.com/rickiyang/p/13265043.html

##### 虚拟文件系统

将操作系统底层的不同文件系统封装起来，为上层提供一个统一规范的文件系统调用接口。

###### 主要模块

1. 超级模块，保存文件元数据；
2. 目录项模块，存储的是目录下的所有文件的inode号和文件名等信息；
3. Inode模块，文件的唯一标识号；
4. 打开文件列表模块，包含所有内核已经打开的文件。已经打开的文件对象由 open 系统调用在内核中创建，也叫**文件句柄**。
5. file_operations 模块。这个模块中维护一个数据结构，是一系列函数指针的集合，其中包含所有可以使用的系统调用函数；
6. address_space 模块，它表示一个文件在页缓存中已经缓存了的物理页。

##### IO缓冲区

buffer 是一个用于**存储速度不同步**的设备或**优先级不同**的设备之间传输数据的区域。一方面，通过缓冲区，可以**使进程之间的相互等待变少**，从而使从速度慢的设备读入数据时，速度快的设备的操作进程不发生间断。另一方面，可以**保护硬盘或减少网络传输的次数**。

###### **Buffer 和 Cache**

cache 是高速缓存，用于 **CPU 和内存**之间的缓冲；

buffer是 I/O 缓存，用于**内存和硬盘**的缓冲。

简单的说，cache 是加速 **读**，而 buffer 是缓冲 **写**，前者解决读的问题，保存从磁盘上读出的数据，后者是解决写的问题，保存即将要写入到磁盘上的数据。

###### **Buffer Cache和 Page Cache**

都是为了处理设备和内存交互时高速访问的问题。buffer cache可称为块缓冲器，page cache可称为页缓冲器。

page cache 面向的是**虚拟内存**，块 I/O 缓存 Buffer cache 是面向**块设备**。

两者最大的区别是**缓存的粒度**。buffer cache 面向的是文件系统的块，而内核的内存管理组件采用了比文件系统的块更高级别的抽象：页(page)，其处理的性能更高。因此**和内存管理交互的缓存组件，都使用页缓存**。

##### 文件读写基本流程

###### **读文件**

1. **进程**调用库函数向**内核**发起读文件**请求**；
2. 内核通过检查进程的**文件描述符**定位到虚拟文件系统的**已打开文件列表项**；
3. 调用该文件可用的**系统调用函数** `read()`；
4. `read()` 函数通过文件表项链接到**目录项模块**，根据传入的文件路径，在目录项模块中检索，找到该文件的 `inode`；
5. 在 `inode` 中，通过**文件内容偏移量计算出要读取的页**；
6. 通过 `inode` 找到文件对应的 `address_space`；
7. 在 `address_space` 中访问该**文件的页缓存树**，查找对应的页缓存结点：
    1. 如果页缓存命中，那么直接返回文件内容；
    2. 如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过`inode` 找到文件该页的磁盘地址，读取相应的页填充该缓存页；
    3. 重新进行第 6 步查找页缓存；
8. 文件内容读取成功。

总结一下：**`inode` 管磁盘，`address_space` 接内存，两者互相指针链接**。

###### **写文件**

前5步和读文件一致，在 `address_space` 中查询对应页的页缓存是否存在；

6. 如果页缓存命中，直接把文件内容修改更新在页缓存的页中，写文件就结束了。这时候**文件修改位于页缓存**，并没有写回到磁盘文件中去。

7. 如果页缓存缺失，那么产生一个页缺失异常，创建一个页缓存页，同时通过 `inode` 找到文件该页的磁盘地址，读取相应的页填充该缓存页。此时缓存页命中，进行第 6 步。
8. 一个页缓存中的页如果被修改，那么会被标记成**脏页**，脏页需要写回到磁盘中的文件块。有两种方式可以把脏页写回磁盘：

1. 手动调用 `sync()` 或者 `fsync()` 系统调用把脏页写回；
2. pdflush 进程会定时把脏页写回到磁盘。

同时注意，脏页不能被置换出内存，如果脏页正在被写回，那么会被设置写回标记，这时候该页就被上锁，其他写请求被阻塞直到锁释放。

##### Linux I/O 读写方式

Linux 提供了**轮询、I/O 中断以及 DMA 传输**这 3 种**磁盘与主存**之间的数据传输机制。其中轮询方式是基于**死循环**对 I/O 端口进行不断检测。I/O 中断方式是指**当数据到达时，磁盘主动向 CPU 发起中断请求，由 CPU 自身负责数据的传输过程**。 DMA 传输则在 I/O 中断的基础上引入了 **DMA 磁盘控制器**，由 DMA 磁盘控制器负责数据的传输，**降低了 I/O 中断操作对 CPU 资源的大量消耗**。

##### 传统IO存在的问题

Linux 系统中，传统的访问方式是通过 `write()` 和 `read()` 两个系统调用实现的，通过 `read()` 函数读取文件到到缓存区中，然后通过 `write()`方法把缓存中的数据输出到网络端口。

![6](校招面经.assets/007S8ZIlgy1ggj9hn3k8zj30hx0cf0uc.jpg)

**上下文切换**：当用户程序向内核发起系统调用时，CPU 将用户进程从用户态切换到内核态；当系统调用返回时，CPU 将用户进程从内核态切换回用户态。**内核态和用户态切换**

**CPU 拷贝**：由 CPU 直接处理数据的传送，数据拷贝时会一直占用 CPU 的资源。

**DMA 拷贝**：由 CPU 向 DMA 磁盘控制器下达指令，让 DMA 控制器来处理数据的传送，数据传送完毕再把信息反馈给 CPU，从而减轻了 CPU 资源的占有率。

基于传统的 I/O **读取方式**，read 系统调用会触发 2 次上下文切换，1 次 DMA 拷贝和 1 次 CPU 拷贝，发起数据读取的流程如下：

1. 用户进程通过`read()`函数向内核 (kernel) 发起系统调用，上下文从用户态 (user space) 切换为内核态 (kernel space)；
2. CPU 利用 DMA 控制器将数据从主存或硬盘拷贝到内核空间 (kernel space) 的读缓冲区 (read buffer)；
3. CPU 将读缓冲区 (read buffer) 中的数据拷贝到用户空间 (user space) 的用户缓冲区 (user buffer)。
4. 上下文从内核态 (kernel space) 切换回用户态 (user space)，read 调用执行返回。

基于传统的 I/O **写入方式**，`write()` 系统调用会触发 2 次上下文切换，1 次 CPU 拷贝和 1 次 DMA 拷贝，用户程序发送网络数据的流程如下：

1. 用户进程通过 `write()` 函数向内核 (kernel) 发起系统调用，上下文从用户态 (user space) 切换为内核态(kernel space)。
2. CPU 将用户缓冲区 (user buffer) 中的数据拷贝到内核空间 (kernel space) 的网络缓冲区 (socket buffer)。
3. CPU 利用 DMA 控制器将数据从网络缓冲区 (socket buffer) 拷贝到网卡进行数据传输。
4. 上下文从内核态 (kernel space) 切换回用户态 (user space)，write 系统调用执行返回。

##### 零拷贝方式

在 Linux 中零拷贝技术主要有 3 个实现思路：用户态直接 I/O、减少数据拷贝次数以及写时复制技术。

- **用户态直接 I/O**：**应用程序可以直接访问硬件存储**，操作系统内核只是辅助数据传输。这种方式依旧存在用户空间和内核空间的上下文切换，硬件上的数据直接拷贝至了用户空间，不经过内核空间。因此，直接 I/O 不存在内核空间缓冲区和用户空间缓冲区之间的数据拷贝。
- **减少数据拷贝次数**：在数据传输过程中，避免数据在用户空间缓冲区和系统内核空间缓冲区之间的CPU拷贝，以及数据在系统内核空间内的CPU拷贝，这也是当前**主流零拷贝技术的实现思路**。
- **写时复制技术**：写时复制指的是**当多个进程共享同一块数据时，如果其中一个进程需要对这份数据进行修改，那么将其拷贝到自己的进程地址空间中，如果只是数据读取操作则不需要进行拷贝操作。**

<img src="校招面经.assets/007S8ZIlgy1ggj9hq79b0j30mo0dst9e.jpg" alt="13" style="zoom: 67%;" />

###### 用户态直接 I/O

使得应用进程或**运行在用户态下的库函数直接访问硬件设备**，数据直接跨过内核进行传输，极大提高了性能。

**缺点：**

1. 只能适用于**不需要内核缓冲区处理的应用程序**，这些应用程序通常在进程地址空间**有自己的数据缓存机制**，称为**自缓存应用程序**，如**数据库管理系统**就是一个代表。
2. 这种方法直接操作磁盘 I/O，由于 **CPU 和磁盘 I/O 之间的执行时间差距，会造成资源的浪费**，解决这个问题需要和**异步 I/O 结合**使用。

###### mmap + write

使用 mmap + write 代替原来的 read + write 方式，减少了 1 次 CPU 拷贝操作。mmap 是 Linux 提供的一种内存映射文件方法，即**将一个进程的地址空间中的一段虚拟地址映射到磁盘文件地址**。

使用 mmap 的目的是**将内核中读缓冲区(read buffer)的地址与用户空间的缓冲区(user buffer)进行映射**，从而实现**内核缓冲区与应用程序内存的共享**，省去了将数据从内核读缓冲区(read buffer)拷贝到用户缓冲区(user buffer)的过程，然而内核读缓冲区(read buffer)仍需将数据拷贝到内核写缓冲区(socket buffer)。

缺陷：

mmap 主要的用处是提高 I/O 性能，特别是针对大文件。对于小文件，内存映射文件反而会**导致碎片空间的浪费**，因为内存映射总是要**对齐页边界**，最小单位是 4 KB，一个 5 KB 的文件将会映射占用 8 KB 内存，也就会浪费 3 KB 内存。

另外 mmap 隐藏着一个**陷阱**，当**使用 mmap 映射一个文件时，如果这个文件被另一个进程所截获，那么 write 系统调用会因为访问非法地址被 SIGBUS 信号终止**，SIGBUS 默认会杀死进程并产生一个 coredump，如果服务器被这样终止那损失就可能不小。

解决这个问题通常使用文件的**租借锁**：首先为文件申请一个租借锁，当其他进程想要截断这个文件时，内核会发送一个实时的 `RT_SIGNAL_LEASE` 信号，告诉当前进程有进程在试图破坏文件，这样 write 在被 SIGBUS 杀死之前，会被中断，返回已经写入的字节数，并设置 errno 为 success。

通常的做法是**在 mmap 之前加锁，操作完之后解锁**。

###### sendfile

sendfile 目的是**简化通过网络在两个通道之间进行的数据传输过程**。sendfile 系统调用的引入，不仅减少了 CPU 拷贝的次数，还减少了上下文切换的次数。

**数据可以直接在内核空间内部进行 I/O 传输**，从而**省去了数据在用户空间和内核空间之间的来回拷贝**。与 mmap 内存映射方式不同的是， sendfile 调用中 I/O 数据**对用户空间是完全不可见**的。也就是说，这是一次完全意义上的数据传输过程。

缺点：

只能适用于那些不需要用户态处理的应用程序。

###### sendfile + DMA gather copy

DMA 辅助的 sendfile可以去掉剩下的一次内核态的拷贝。简单说就是利用DMA进行从读缓冲区到网卡的拷贝操作，减少CPUcopy。

###### splice

sendfile 只适用于将数据从文件拷贝到 socket 套接字上，同时需要硬件的支持，这也限定了它的使用范围。Linux 在 2.6.17 版本引入 splice 系统调用，不仅不需要硬件支持，还实现了**两个文件描述符之间的数据零拷贝**。

在内核空间的读缓冲区 (read buffer) 和网络缓冲区 (socket buffer) 之间**建立管道** (pipeline)，从而避免了两者之间的 CPU 拷贝操作。

splice 拷贝方式也同样存在用户程序不能对数据进行修改的问题。除此之外，它使用了 Linux 的管道缓冲机制，可以用于任意两个文件描述符中传输数据，但是它的**两个文件描述符参数中有一个必须是管道设备**。

###### 写时复制

在某些情况下，内核缓冲区可能被多个进程所共享，如果某个进程想要这个共享区进行 write 操作，由于 write 不提供任何的锁操作，那么就会对共享区中的数据造成破坏，写时复制的引入就是 **Linux 用来保护数据的**。

写时复制指的是当多个进程共享同一块数据时，如果其中一个进程需要对这份数据进行修改，那么就需要将其拷贝到自己的进程地址空间中。这样做并不影响其他进程对这块数据的操作，**每个进程要修改的时候才会进行拷贝**，所以叫写时拷贝。这种方法在某种程度上能够降低系统开销，如果某个进程永远不会对所访问的数据进行更改，那么也就永远不需要拷贝。

缺点：

需要 MMU 的支持，**MMU 需要知道进程地址空间中哪些页面是只读的**，**当需要往这些页面写数据时，发出一个异常给操作系统内核，内核会分配新的存储空间来供写入的需求**。

###### 缓冲区共享

缓冲区共享方式完全改写了传统的 I/O 操作，传统的 Linux I/O 接口支持数据在应用程序地址空间和操作系统内核之间交换，这种交换操作导致所有的数据都需要进行拷贝。

如果采用 fbufs 这种方法，**需要交换的是包含数据的缓冲区**，这样就消除了多余的拷贝操作。应用程序将 fbuf 传递给操作系统内核，这样就能减少传统的 write 系统调用所产生的数据拷贝开销。

同样的应用程序通过 fbuf 来接收数据，这样也可以减少传统 read 系统调用所产生的数据拷贝开销。

fbuf 的思想是**每个进程都维护着一个缓冲区池，这个缓冲区池能被同时映射到用户空间 (user space) 和内核态 (kernel space)，内核和用户共享这个缓冲区池，这样就避免了一系列的拷贝操作**。

缺点：

缓冲区共享的难度在于管理共享缓冲区池需要应用程序、网络软件以及设备驱动程序之间的紧密合作，而且如何改写 API 目前还处于试验阶段并不成熟。

##### Linux零拷贝对比

无论是传统 I/O 拷贝方式还是引入零拷贝的方式，**2 次 DMA Copy** 是都少不了的，因为两次 DMA 都是依赖硬件完成的。

| 拷贝方式                   | CPU拷贝 | DMA拷贝 |   系统调用   | 上下文切换 |
| -------------------------- | :-----: | :-----: | :----------: | :--------: |
| 传统方式(read + write)     |    2    |    2    | read / write |     4      |
| 内存映射(mmap + write)     |    1    |    2    | mmap / write |     4      |
| sendfile                   |    1    |    2    |   sendfile   |     2      |
| sendfile + DMA gather copy |    0    |    2    |   sendfile   |     2      |
| splice                     |    0    |    2    |    splice    |     2      |

#### 6.虚拟内存？怎么写虚拟内存？

**虚拟内存的重要意义是它定义了一个连续的虚拟地址空间**，并且 **把内存扩展到硬盘空间**。虚拟内存让进程有独享地址空间的错觉。让程序可以**拥有超过系统物理内存大小的可用内存空间**。

涉及到**swap交换空间，局部性原理（时间，空间），虚拟存储器**。

##### 技术实现

**虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。** 

1. **请求分页存储管理** ：分页存储管理+请求**调页功能和页面置换**功能。
2. **请求分段存储管理** ：分段存储管理+**请求调段功能、分段置换**功能。
3. **请求段页式存储管理**

**请求分页存储管理不要求将作业全部地址空间同时装入主存**。基于这一点，请求分页存储管理可以提供虚存，而分页存储管理却不能提供虚存。

当一个进程试图访问虚拟地址空间中的某个数据时，会经历下面两种情况的过程：

1. CPU想访问某个虚拟内存地址，**找到进程对应的页表中的条目**，**判断有效位**
2. 如果有效位为1，说明在页表条目中的物理内存地址不为空，根据物理内存地址，访问物理内存中的内容，返回
3. 如果有效位为0，但页表条目中还有地址，这个地址是磁盘空间的地址，这时触发**缺页异常**，系统把物理内存中的一些数据拷贝到磁盘上，腾出所需的空间，并且**更新页表**。此时重新执行访问之前虚拟内存的指令

#### 7.页表，实现机制

进程的页式存储方式是**分散存储**的。

页表是一种特殊的数据结构，存放着各个虚拟页的状态，是否映射，是否缓存.。进程要知道哪些内存地址上的数据在物理内存上，哪些不在，还有在物理内存上的哪里，这就需要用页表来记录。页表的每一个表项分为两部分，第一部分记录此页是否在物理内存上，第二部分记录物理内存页的地址(如果在的话)。当进程访问某个虚拟地址，就会先去看页表，如果发现对应的数据不在物理内存中，则发生缺页异常。

**每一个进程**，只要在内存里面，就会拥有一张**页表**，页表也保存在内存里面。
进程内部，把程序和数据按照页框大小进行划分，分别保存，起始页码为0。在**页表中，包含与进程分页数相同数量的页表项**，每一个页表项由两部分组成，即**页号和其对应物理地址**（即物理块号，也是页框号），物理地址对应的页号=页表始址+页号*页表项长度（地址变换机构的硬件操作）。
在进程没有处于运行状态，但是存在于内存当中时，**进程控制块PCB中会保存页表在内存中的存储位置**，即始址+长度。
当进程转为运行状态，操作系统会根据PCB，把PCB中的页表信息调进**页表寄存器PTR**，地址变换机构根据页表、地址（页号、偏移量）找到相应程序和数据进行运行。

#### 8.多线程如何实现线程安全？

##### 同步

###### 阻塞（加锁）

无论共享数据是否真的会出现竞争，它都要进行加锁。

###### 非阻塞（CAS）

**基于冲突检测的乐观并发策略**，先进行操作，如果没有其他线程争用共享数据，那操作就成功了；如果共享数据有争用，产生了冲突，那就再采用其他的**补偿措施**。

非阻塞的实现CAS（compareandswap）：CAS指令需要有3个操作数，分别是**内存地址、旧的预期值**（用A表示）和**新值**（用B表示）。CAS指令执行时，CAS指令指令时，当且仅当V处的值符合旧预期值A时，处理器用B更新V处的值，否则它就不执行更新，但是**无论是否更新了V处的值，都会返回V的旧值**，上述的处理过程是一个**原子操作**。

**CAS缺点：**

​    **ABA问题**：因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。

​    ABA问题的**解决思路就是使用版本号**。在变量前面追加版本号，每次变量更新的时候把版本号加一，那么A-B-A就变成了1A-2B-3C。

##### 无同步

###### 可重入代码

可重入代码（ReentrantCode）也称为纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码，而在控制权返回后，原来的程序不会出现任何错误。**所有的可重入代码都是线程安全的，但是并非所有的线程安全的代码都是可重入的**。 可重入代码的特点是**不依赖存储在堆上的数据和公用的系统资源、用到的状态量都是由参数中传入、不调用非可重入的方法等。**

###### 线程本地存储

把共享数据的**可见范围**限制在同一个线程之内。这样无需同步也能保证线程之间不出现数据的争用问题。

消费队列的架构模式（如“**生产者-消费者**”模式）都会将产品的消费过程尽量在一个线程中消费完。Web中一个请求对应一个服务器线程（Thread-per-Request）”的处理方式也是。

#### 9.可重入锁

可重入就是说某个线程已经获得某个锁，可以再次获取锁而不会出现死锁。

#### 10.Linux文件系统

#### 11.Linux命令

tail pwd chmod losf netstat top

#### 12.为什么线程的切换比协程慢？

主要在于**线程切换需要借助内核完成**，意味着 用户态 --> 内核态 --> 用户态，
而**协程切换只在用户态就可以完成**， 用户态 --> 用户态

用户态和内核态的切换是一部分的开销

切换频率，**线程切换频率比协程切换的频率高很多**， 因为协程库大多都在 IO 阻塞才切换.还有协程是串行的，线程是并行的，**协程是自主让渡执行时间，而且都跑在一个核心上，不需要复杂的调度算法**，不需要优先级管理，而线程，其自身不让渡核心时间，还有优先级。 操作系统需要像指挥交通那样指挥，所以耗时。

#### 13.socket相关

#### 14.cpu的上下文切换问题

##### CPU 上下文

在每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，**需要系统事先帮它设置好 CPU 寄存器和程序计数器**(Program Counter，PC)。**CPU 寄存器**，是 CPU 内置的容量小、但速度极快的内存。而**程序计数器，则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置**。它们都是 CPU 在运行任何任务前，**必须的依赖环境**，因此也被叫做 CPU 上下文。而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。

**根据任务的不同**，CPU的上下文切换可以分为不同的场景，也就是进程上下文切换、线程上下文切换、中断上下文切换。

##### **进程上下文切换**

进程既可以在用户空间运行，又可以在内核空间中运行。进程在用户空间运行时，被称为进程的用户态，而陷入内核空间的时候，被称为进程的内核态。从用户态到内核态的转变，需要通过系统调用来完成。**系统调用的过程发生 CPU 上下文的切换**。

CPU 寄存器里原来用户态的指令位置，需要先保存起来。接着，为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。而系统调用结束后，CPU 寄存器需要恢复原来用户保存的状态，然后再切换到用户空间，继续运行进程。所以，**一次系统调用的过程，其实是发生了两次 CPU 上下文切换**。不过，需要注意的是，系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，也不会切换进程。这跟我们通常所说的进程上下文切换是不一样的：

- 进程上下文切换，是指从一个进程切换到另一个进程运行。
- 而系统调用过程中一直是同一个进程在运行。

系统调用过程通常称为特权模式切换，而不是上下文切换。但实际上，系统调用过程中，CPU 的上下文切换还是无法避免的。

###### 进程上下文切换跟系统调用又有什么区别呢?

**进程是由内核来管理和调度的，进程的切换只能发生在内核态**。所以，进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。

因此，进程的上下文切换就比系统调用时多了一步：在保存当前进程的**内核状态和 CPU 寄存器**之前，需要先把该**进程的虚拟内存、栈**等保存下来;而加载了下一进程的内核态后，还需要**刷新进程的虚拟内存和用户栈**。

如下图所示，保存上下文和恢复上下文的过程并不是“免费”的，需要内核在 CPU 上运行才能完成。

##### **线程上下文切换**

 线程与进程最大的区别在于，**线程是调度的基本单位，而进程则是资源拥有的基本单位**。说白了，所谓**内核中的任务调度，实际上的调度对象是线程;而进程只是给线程提供了虚拟内存、全局变量等资源**。所以，对于线程和进程，我们可以这么理解：

- 当进程只有一个线程时，可以认为进程就等于线程。
- 当进程拥有多个线程时，这些线程会**共享相同的虚拟内存和全局变量等资源**。这些资源在上下文切换时是不需要修改的。
- 另外，**线程也有自己的私有数据，比如栈和寄存器**等，这些在上下文切换时也是需要保存的。

这么一来，线程的上下文切换其实就可以分为两种情况：

​    第一种， **前后两个线程属于不同进程**。此时，因为资源不共享，所以**切换过程就跟进程上下文切换是一样**。

​    第二种，**前后两个线程属于同一个进程**。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。

##### **中断上下文切换**

​    为了快速响应硬件的事件，**中断处理会打断进程的正常调度和执行，转而调用中断处理程序**，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。

**对同一个 CPU 来说，中断处理比进程拥有更高的优先级**，所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。

另外，跟进程上下文切换一样，中断上下文切换也需要消耗 CPU，切换次数过多也会耗费大量的 CPU，甚至严重降低系统的整体性能。所以，当你发现中断次数过多时，就需要注意去排查它是否会给你的系统带来严重的性能问题。

#### 15.755是什么权限？

拥有者可读可写可执行 群组可读可执行 其他组可读可执行

#### 16.linux 查找当前文件后20行

tail -n 20 filename

#### 17.Linux统计字符出现的个数

Grep -o objStr filename|wc - l

#### 18.Linux的进程调度算法

##### 1. 批处理系统

**批处理系统**没有太多的用户操作，在该系统中，调度算法目标是**保证吞吐量和周转时间**（从**提交到终止**的时间）。

###### ① 先来先服务first-come first-serverd（FCFS）

按照请求的顺序进行调度。

有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

###### ② 短作业优先shortest job first（SJF）

按估计运行时间**最短**的顺序进行调度。

长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

###### ③ 最短剩余时间优先shortest remaining time next（SRTN）

按估计剩余时间最短的顺序进行调度。

##### 2. 交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是**快速地进行响应**。

###### ① 时间片轮转算法

将所有就绪进程按 **FCFS** (先来先服务)的原则排成一个队列，每次调度时，把 CPU 时间分配给**队首进程**，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟**中断**，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和**时间片的大小**有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

###### ② 优先级调度算法

为每个进程分配一个**优先级**，按优先级进行调度。

为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

###### ③ 多级反馈队列算法

一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要**交换 100 次**。

多级队列是为这种需要**连续执行多个时间片**的进程考虑，它设置了**多个队列**，每个队列时间片大小都不同，例如 1, 2, 4, 8 ,..。进程在第一个队列没执行完，就会被移到**下一个队列**。这种方式下，之前的进程只需要交换 7 次。

每个**队列优先权**也不同，最上面的优先权最高。因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

可以将这种调度算法看成是**时间片轮转调度算法和优先级调度算法**的**==结合==**。UNIX 操作系统采取的便是这种调度算法。

#### 19.Linux的watch和Ctrl+C是怎么实现的？

##### linux下的watch命令

在linux下，watch是**周期性的执行下一个命令，并全屏显示执行结果**。

- -n --interval 指定间隔时间
- -d --differences 高亮显示变化的区域
- -d=cumulative 把变动过的地方都高亮显示，不管最近的那次有没有变动
- -t --no-title 关闭watch命令在屏幕顶部的时间间隔、命令和时间的输出

FreeBSD和Linux下watch命令不同。在Linux下，watch是周期性的执行下一个程序，并全屏显示执行结果。而FreeBSD下的watch命令是查看其它用户的正在运行的操作，watch允许你偷看其它terminal正在做的事，前提是超级用户。

#### 20.内存泄漏和内存溢出的区别？有什么危害？

内存溢出是分配的内存空间被使用完，无可用空间。而内存泄漏是分配的内存由于某些原因，导致无法被回收，时间久了也会导致内存溢出。

#### 21.分页和分段内存管理有什么区别？

(1) **页是信息的物理单位**，分页是**为实现离散分配方式**，以消减内存的外零头，提高内存的利用率。**段则是信息的逻辑单位**，它含有**一组其意义相对完整的信息**。分段的目的是为了能**更好地满足用户的需要**。

(2) 页的大小固定且由系统决定；而段的长度却不固定，决定于用户所编写的程序。

(3) **分页的地址空间是一维的**，程序员只需利用一个记忆符，即可表示一个地址；而**分段的作业地址空间是二维**的，程序员在标识一个地址时，既需给出**段名，又需给出段内地址**。

#### 22.copy是操作符还是内置函数？

#### 23.进程的五种状态及状态间转移

![image-20210223110816753](校招面经.assets/image-20210223110816753.png)

- 新创建态
- 就绪状态（ready）：等待被调度
- 运行状态（running）
- 阻塞状态（waiting）：等待资源
- 结束态

应该注意以下内容：

- 只有就绪态和运行态可以**相互转换**，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

#### 24.僵尸进程和孤儿进程，有什么危害？

##### 孤儿进程

一个**父进程**退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。

孤儿进程将被 **init 进程**（进程号为 1）所收养，并由 init 进程对它们完成**状态收集工作**。

由于孤儿进程会被 init 进程收养，所以孤儿进程不会对系统造成危害。

##### 僵尸进程

一个子进程的进程描述符在子进程退出时不会释放，**只有当父进程通过 wait() 或 waitpid() 获取了子进程信息后才会释放**。如果**子进程退出，而父进程并没有调用 wait() 或 waitpid()**，那么子进程的**进程描述符**仍然保存在系统中，这种进程称之为僵尸进程。

僵尸进程通过 ps 命令显示出来的状态为 **Z（zombie）**。

系统所能使用的进程号是有限的，如果产生大量僵尸进程，将因为**没有可用的进程号**而导致系统不能产生新的进程。

要**消灭**系统中大量的僵尸进程，只需要将其**父进程**杀死，此时僵尸进程就会变成孤儿进程，从而被 init 进程所收养，这样 init 进程就会释放所有的僵尸进程所占有的资源，从而结束僵尸进程。

#### 25.硬链接和软链接

##### 1. 实体链接（硬链接）

在目录下创建一个条目，记录着**文件名与 inode 编号**，这个 inode 就是**源文件的 inode**。

**删除任意一个**条目，文件还是**存在**，只要**引用数量不为 0**。

有以下限制：**不能跨越文件系统、不能对目录进行链接**。

##### 2. 符号链接（软链接）

符号链接文件保存着**源文件所在的绝对路径**，在读取时会定位到**源文件**上，可以理解为 **Windows 的快捷方式。**

当**源文件**被删除了，链接文件就**打不开**了。

因为记录的是**路径**，所以可以为**==目录==建立链接**。

#### 26.TCP time_wait状态存在的原因

**客户端**接收到服务器端的 **FIN 报文**后进入此状态，此时**并不是直接进入 CLOSED** 状态，还需要等待一个**时间计时器**设置的时间 **2MSL**。这么做有两个理由：

- 确保**最后一个确认报文**能够到达。如果 **B 没收到** A 发送来的**确认报文**，那么就会**重新发送连接释放**请求报文，A 等待一段时间就是为了处理这种情况的发生。
- 等待一段时间是为了让本连接持续时间内所产生的**所有报文都从网络中消失**，使得下一个新的连接**不会出现旧的连接**请求报文。

#### 27.**Linux如何从网卡驱动中读取数据？**

#### 28.计算机组成部分

运算器、控制器、存储器、输入设备和输出设备

#### 29.socket如何标识

#### 30.二进制的原码反码，补码

##### 原码

一个正数，转换为二进制位就是这个正数的原码。负数的绝对值转换成二进制位然后在高位补1就是这个负数的原码。

##### 反码

正数的反码就是原码，负数的反码等于**原码除符号位以外所有的位取反。**

##### 补码

正数的补码与原码相同，负数的补码为其原码除符号位外所有位取反（得到反码了），然后最低位加1.

#### 31.计算机中的文字乱码，字符集和字符编码的含义、如何区分？（[文章](https://www.cnblogs.com/skynet/archive/2011/05/03/2035105.html)）

#### 32.程序的压栈出栈含义

堆栈是RAM中划出的一片特殊存储区，用于临时存放一些重要数据（这些数据存放一会后是必须回到原位的），其中数据的位置由堆栈指针确定，而数据的存放和读取则由入栈指令和出栈指令控制，入出必须对应成对的使用才能使压入的数据正确的回到压入前的位置。
比如：当前正在运行某程序，要调用一个子程序，而子程序中会用到A、B、C三单元，主程序中这三个单元中现有的信息在子程序运行结束后还要继续用的，那么就需要用堆栈临时保存这些数据，等子程序结束后再还原。入栈时是压入A、压入B、压入C，出栈则必须是出C、出B、出A。这就好比子弹夹，先压进去的子弹在下，后压进去的在上，子弹进入枪膛（相当于出栈）则是相反，先上面后下面，正如一楼“一叠盘子”的比喻。这种用法的约定，是堆栈本身特性决定的，必须遵守。

#### 33.Linux awk指令

awk是一个强大的**文本分析工具**，相对于grep的查找，sed的编辑，awk在其**对数据分析并生成报告时**，显得尤为强大。简单来说awk就是**把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。**

#### 34.对缓存的理解

系统层面（L1、L2、L3）、网络层面（浏览器缓存）、服务器层面（redis）

#### 35.Linux nginx日志文件找出次数最多的IP

sort、uniq、awk

#### 36.Linux 查看一个端口的运行情况

```shell
查看到进程占用的端口号
netstat -anp | grep pid
```

#### 37.用过定时任务吗？

Corn

#### 38.常用的shell命令

#### 39.Linux内核了解

#### 40.mmu内存管理单元

有时称作**分页内存管理单元**（英语：**paged memory management unit**，缩写为**PMMU**）。它是一种负责处理中央处理器（CPU）的内存访问请求的计算机硬件。它的功能包括虚拟地址到物理地址的转换（即虚拟内存管理）、内存保护、中央处理器高速缓存的控制。

除了提供虚拟内存管理，让应用程序可以使用超出物理内存的空间之外，还对实际的物理内存进行分割和保护，使得每个软件任务只能访问其分配到的内存空间。如果某个任务试图访问其他任务的内存空间，内存管理单元将自动产生异常，保护其他任务的程序和数据不受破坏。

#### 41.死锁

##### 必要条件

- **互斥**：每个资源要么已经分配给了一个进程，要么就是可用的。
- **占有和等待**：已经得到了某个资源的进程可以**再请求新**的资源。
- **不可抢占**：已经分配给一个进程的资源**不能强制性地被抢占**，它只能被占有它的进程**显式地释放**。
- **环路等待**：有两个或者两个以上的**进程组成一条环路**，该环路中的每个进程都在等待下一个进程所占有的资源。

##### 处理死锁

- **鸵鸟策略**
- **死锁检测与死锁恢复**
    - 利用**抢占**恢复
    - 利用**回滚**恢复
    - 通过**杀死进程**恢复
- **死锁预防** 
- **死锁避免**

#### 42.在linux下怎么查找一个日志文件一个方法返回的不同code码的个数

#### 43.如何解决孤儿进程的出现？

#### 44.一个文件中去重后的IP地址数目

Awk

#### 45.如何查看某个进程占用的内存大小？

ps aux | grep xxx

#### 46.内存分页的目的？

分页机制允许进程的物理地址空间可以是非连续的（因而一些**内存碎片**可以得到利用）
而且**交换空间**也是’分为‘同样大小的页，在将内存块备份到交换空间时更容易处理

#### 47.线程共享的有什么？不共享的有什么？协程呢？

##### 线程共享

###### 资源

- 堆。由于堆是在进程空间中开辟出来的，所以它是理所当然地被共享的;
- 全局变量。全局变量它是与具体某一函数无关的，所以也与特定线程无关;因此也是共享的

###### 环境

进程**代码段**，进程的**公有数据**（利用这些共享的数据，线程很容易的实现相互之间的通讯），进程**打开的文件描述符**，信号的处理器，进程的**当前目录和进程用户ID与进程组ID**。

##### 线程独享

###### 资源

- 栈
- 寄存器。每个线程里存放着寄存器的副本是不一样的

###### 个性

- 线程ID
- 寄存器组的值
- 线程的堆栈
- 错误返回码
- 线程的信号屏蔽码
- 线程的优先级

##### 协程共享

全局变量

堆

##### 协程不共享

栈

#### 48.死锁的必要条件

- 互斥
- 占有和等待
- 不可抢占
- 环路等待

#### 49.死锁的预防

###### ① 破坏互斥条件

例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

###### ② 破坏占有和等待条件

一种实现方式是规定所有进程在**开始执行前请求所需要的全部资源**。

###### ③ 破坏不可抢占条件

###### ④ 破坏环路等待

给资源**统一编号**，进程只能**按编号顺序**来请求资源。

##### 50. 死锁避免

1. 判断“系统安全状态”法

在进行系统资源分配之前，**先计算此次资源分配的安全性**。若此次分配不会导致系统进入不安全状态，则将资源分配给**进程； 否则，让进程**等待。 

2. 银行家算法
    - 申请的贷款额度不能超过银行现有的资金总额
    - 分批次向银行提款，但是贷款额度不能超过一开始最大需求量的总额
    - 暂时不能满足客户申请的资金额度时，在有限时间内给予贷款
    - 客户要在规定的时间内还款

#### 50.vim怎么查询一个单词，怎么做匹配？

1. 从头搜索：/hello
2. 从尾搜索：?hello
3. 精确搜索："<“表示匹配单词开头，”>“表示匹配单词末尾，匹配完整单词”?<hello>“或者”/<hello>"。如输入"/hel"、"/<hel"、"/llo>"，可能搜索到hello

#### 51.说几个你常用的Linux命令

#### 52.怎么判断一个进程的状态，用什么命令

1. 如果想看进程的基本信息bai，ps就可以了，但ps查看的时间其实是真正cpu运行的时间，而不是程序启动的时间，如下

```shell
[root@e conf]# ps -e|grep ps
383 ? 00:00:00 kpsmoused
17287 pts/1 00:00:00 ps

```

2. 如果想看更详细的信息，可以用-o选项，选择要查看的项目

```shell
[root@e conf]# ps -eo pid,lstart,cmd|grep sshd
2153 Fri Dec 21 17:21:10 2012 sshd: root@pts/2
16902 Thu Dec 27 09:08:50 2012 sshd: root@notty
17309 Thu Dec 27 11:28:43 2012 grep sshd
18397 Tue Dec 25 14:00:38 2012 /usr/sbin/sshd
18399 Tue Dec 25 14:00:41 2012 sshd: root@notty
23272 Wed Dec 26 15:40:58 2012 sshd: root@pts/1
其中pid表示进程号，lstart是启动时间
另外还有etime 表示运行的时间， nlwp表示线程数，详细的可以看help
```

3. 查看进程的状态信息

    Linux下进程的详细信息会被记录在``/proc/PID/status`文件中，其中PID为某个进程的Process ID。现在假设有个程序ID为788，那么我们只要

    ```shell
    cat /proc/788/status
    ```

    至于如何得到PID，可以用”ps aux | grep ‘进程名’” 找到pid.

ps工具标识进程的5种状态码:

- D 不可中断 uninterruptible sleep (usually IO)
- R 运行 runnable (on run queue)
- S 中断 sleeping
- T 停止 traced or stopped
- Z 僵死 a defunct ("zombie") process

#### 53.vim怎么跳到最前面，怎么跳到最后面

```
:0或:1跳到文件第一行
:$跳到文件最后一行
```

#### 54.一个文件太大应该怎么打开

在Linux下用VIM打开大小几个G、甚至几十个G的文件时，是非常慢的。

这时，我们可以利用下面的方法**分割文件，然后再打开**:

1. 查看文件的前多少行

    ```shell
    head -10000 /var/lib/mysql/slowquery.log > temp.log
    上面命令的意思是：把slowquery.log文件前10000行的数据写入到temp.log文件中。
    ```

2. 查看文件的后多少行

```shell
tail -10000 /var/lib/mysql/slowquery.log > temp.log
上面命令的意思是：把slowquery.log文件后10000行的数据写入到temp.log文件中。
```

3. 查看文件的几行到几行

```shell
sed -n '10,10000p' /var/lib/mysql/slowquery.log > temp.log
上面命令的意思是：把slowquery.log文件第10到10000行的数据写入到temp.log文件中。
```

4. 根据查询条件导出

```shell
cat catalina.log | grep  '2017-09-06 15:15:42' > test.log
```

5. 实时监控文件输出

```shell
tail -f catalina.out
```

#### 55.怎么查看cpu，磁盘io，网络io

##### top

整机查看，内存，CPU，进程数等

##### uptime

系统性能命令的精简版

##### CPU：vmstat 

vmstat -n 2 3 :系统采样，2秒间隔，采样3次
一般vmstat工具的使用是通过两个数字参数来完成的，第一个参数是采样的时间间隔数单位是秒，第二个参数是采样的次数

##### 查看所有CPU核信息 :mpstat 

```shell
mpstat [选项][<时间间隔>[<次数>]]
```

##### 内存：free

一般都使用 free -m 查看全部内存

##### 查看进程占用内存：pidstat -p 进程号 -r  采样间隔秒数

##### 硬盘：df

查看磁盘剩余空闲数

df：命令查询出来的是字节

df -h 用人类能看懂的方式打开

##### 磁盘IO：iostat

磁盘I/O性能评估命令：iostat -xdk 2 3,   2s间隔，3次

###### 查看进程占用的磁盘IO

pidstat -d 采样间隔秒数 -p 进程号

#####  网络IO：ifstat

默认本地没有，下载ifstat

#### 56.怎么查看一个文件的大小 

1. 最简单的查看方法可以使用`ls -ll、ls-lh`命令进行查看，当使用ls -ll，会显示成**字节大小**，而ls- lh会以KB、MB等为单位进行显示，这样比较直观一些。
2. 通过命令`du -h –max-depth=1 *`，可以**查看当前目录下各文件、文件夹的大小**，这个比较实用。
3. **查询当前目录总大小**可以使用`du -sh`，其中s代表统计汇总的意思，即只输出一个总和大小。

#### 57.怎么看端口占用情况

##### lsof

lsof(list open files)是一个列出当前系统打开文件的工具。

lsof 查看端口占用语法格式：

```sh
lsof -i:端口号
```

需要 root 用户的权限来执行

##### netstat

**netstat -tunlp** 用于显示 tcp，udp 的端口和进程等相关情况。

netstat 查看端口占用语法格式：

```shell
netstat -tunlp | grep 端口号
```

- -t (tcp) 仅显示tcp相关选项
- -u (udp)仅显示udp相关选项
- -n 拒绝显示别名，能显示数字的全部转化为数字
- -l 仅列出在Listen(监听)的服务状态
- -p 显示建立相关链接的程序名

#### 58.grep怎么用

Linux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。

[options]主要参数：

－c：只输出匹配行的计数。
－I：不区分大 小写(只适用于单字符)。
－h：查询多文件时不显示文件名。
－l：查询多文件时只输出包含匹配字符的文件名。
－n：显示匹配行及 行号。
－s：不显示不存在或无匹配文本的错误信息。
－v：显示不包含匹配文本的所有行。
pattern正则表达式主要参数：
\： 忽略正则表达式中特殊字符的原有含义。
^：匹配正则表达式的开始行。
$: 匹配正则表达式的结束行。
\<：从匹配正则表达 式的行开始。
\>：到匹配正则表达式的行结束。
[ ]：单个字符，如[A]即A符合要求 。
[ - ]：范围，如[A-Z]，即A、B、C一直到Z都符合要求 。
。：所有的单个字符。
\* ：有字符，长度可以为0。

#### 59.怎么看一个进程主要是哪个函数在消耗性能？

使用`GNU profiler(gprof)`工具可对程序的**函数调用次数，函数占用时间**，精确展示。是程序开发的一个有用的工具。

用法：在**编译时加入 gcc -pg 选项**。正常运行程序后，会产生一个gmon.out文件.

通过如下命令可查看程序运行中各函数调用次数以及运行时间。

```shell
$ gprof app gmon.out > report.txt
```

输出结果会展示在report文件中。

#### 60.怎么定位一个300万次中出现一次的错误



#### 61.怎么杀死一个进程

- kill - 通过进程 ID 来结束进程
- killall - 通过进程名字来结束进程 

kill 发送SIGTERM（15）信号给进程，告诉进程，你需要被关闭，请自行停止运行并退出。kill -9 发送SIGKILL信号给进程，告诉进程，你被终结了，请立刻退出。

TERM(或数字9）表示“无条件终止”；因此 kill - 9 表示强制杀死该进程；与SIGTERM相比，这个**信号不能被捕获或忽略，同时接收这个信号的进程在收到这个信号时不能执行任何清理。**

最经常使用的结束进程的信号是：

| Signal Name | Single Value | Effect         |
| :---------- | :----------- | :------------- |
| SIGHUP      | 1            | 挂起           |
| SIGINT      | 2            | 键盘的中断信号 |
| SIGKILL     | 9            | 发出杀死信号   |
| SIGTERM     | 15           | 发出终止信号   |
| SIGSTOP     | 17, 19, 23   | 停止进程       |

#### 62.协程为什么比线程轻量级

因为协程不需要进行用户态到内核态的切换，协程的整个调度在用户程序层面进行。协程占用的资源量更小，同时在一个线程上运行，不存在写变量冲突的问题，共享资源不需要加锁，所以可以减少大量的开销。

#### 63.协程怎么绑定线程的？

#### 64.协程怎么调度？

协程是编译器级别的，通过插入相关的代码使得代码段能够实现分段式的执行，**重新开始的地方是yield关键字指定的，一次一定会跑到一个yield对应的地方**。

GMP调度模型采取的是任务队列型的调度。

#### 65.虚拟内存和物理内存的关系

虚拟内存是一个**连续的地址空间（这也只是进程认为），而实际上，它通常是被分隔成多个物理内存碎片，还有一部分存储在外部磁盘存储器上，在需要时进行数据交换。**

进程开始要访问一个地址，它可能会经历下面的过程：

1. 每次我要访问地址空间上的某一个地址，都需要**把地址翻译为实际物理内存地址**，所有进程共享这整一块物理内存，**每个进程只把自己目前需要的虚拟地址空间映射到物理内存上**
2. 进程需要知道**哪些地址空间上的数据在物理内存上，哪些不在**（可能这部分存储在磁盘上），还有在物理内存上的哪里，这就需要通过**页表来记录**
3. 页表的每一个表项分两部分，第一部分记录此页是否在物理内存上，第二部分记录物理内存页的地址（如果在的话）
4. 当进程访问某个虚拟地址的时候，就会先去看页表，如果**发现对应的数据不在物理内存上，就会发生缺页异常**
5. 缺页异常的处理过程，操作系统立即阻塞该进程，并将硬盘里对应的页换入内存，然后使该进程就绪，如果内存已经满了，没有空地方了，那就找一个页覆盖，至于具体覆盖的哪个页，就需要看操作系统的页面置换算法是怎么设计的了。

#### 66.内核态和用户态切换为什么会消耗性能？

程序执行到**系统调用**时，首先使用类似int 80H的软中断指令，**保存现场**，去的系统调用号，在内核态执行，然后恢复现场，每个进程都会有两个栈，一**个内核态栈和一个用户态栈**。当执行int中断执行时就会由用户态，栈转向内核栈。**系统调用时需要进行栈的切换**。而且内核代码对用户不信任，需要进行额外的检查。**系统调用的返回过程有很多额外工作，比如检查是否需要调度等**。 

系统调用一般都需要**保存用户程序的上下文**(context), 在进入内核得时候需要保存用户态得寄存器，在内核态返回用户态得时候会恢复这些寄存器得内容。这是一个开销的地方。 如果需要在不同用户程序间切换的话，那么还要更新cr3寄存器，这样会更换每个程序的虚拟内存到物理内存映射表的地址，也是一个比较高负担的操作。

#### 67.协程如果像你说的这么牛逼，为什么只有Go支持呢，其他语言为什么这一两年才开始有协程库？协程这个概念好多年前就有了不是吗？

**协程的好处：**

- 无需线程上下文切换的开销
- 无需原子操作锁定及同步的开销
- 方便切换控制流，简化编程模型
- 高并发+高扩展性+低成本：一个CPU支持上万的协程都不是问题。所以很适合用于高并发处理。

 **缺点：**

- **无法利用多核资源**：协程的**本质是个单线程**,它不能同时将 单个CPU 的多个核用上,**协程需要和进程配合才能运行在多CPU上**.当然我们日常所编写的绝大部分应用都没有这个必要，除非是cpu密集型应用。
- **进行阻塞（Blocking）操作（如IO时）会阻塞掉整个程序**：这一点和事件驱动一样，可以使用异步IO操作来解决

### 4.算法

#### 1.单链表快排

#### 2.建堆过程

#### 3.建堆复杂度，手算

#### 4.MaxStack

#### 5.pop push

#### 6.getMax

#### 7.lru实现？队列？优化？

#### 8.算法：最大栈，最小栈

#### 9.对数组进行堆排序

#### 10.二分查找，1, 2, 3, 3, 4, 4, 4, 4, 4, 5, 5, 8, 10, 12——递增数列中某个数出现的次数

#### 11.求根号n，精度小数点后6位

#### 12.奇数升序偶数降序链表，合并成一个升序链表

#### 13.两个协程交替打印1到20，先用锁，再用channel

#### 14.[在二叉树中找到累加和为指定值的最长路径长度](https://www.nowcoder.com/jump/super-jump/practice?questionId=633)

#### 15.高精度除法

#### 16.自己实现一个map数据结构，实现添加，删除操作

#### 17.二叉树层序遍历

#### 18.一堆数都出现两次，就两个出现一次，找这两个数

#### 19.判断二叉树是否镜像二叉树

#### 20.堆排序

#### 21.快排

#### 22.链表翻转

#### 23.对链表进行排序

#### 24.计算二叉树所有左叶子节点的和

#### 25.n对括号输出所有合法的情况

#### 26.n个有序的数组合并成一个

#### 27.给n个数1-n,随机n次,将这n个数输出

#### 28.二叉树中序遍历，递归和非递归两种

#### 29.单链表找中间节点

####  30.给定一个二叉树和其中的一个节点，请找出中序遍历顺序的下一个结点并且返回。注意，树中的结点不仅包含左右子结点，同时包含指向父结点的指针。

#### 31.手写LRU结构，增删改查

#### 32.实现一个线程池，说原理和数据结构

#### 33.算法

输入一个整型数组，数组中的一个或连续多个整数组成一个子数组。求所有子数组的和的最大值。 

 输入**:** array = [-2,1,-3,4,-1,2,1,-5,4] 

 输出**:** 6 

 解释**:** 连续子数组 [4,-1,2,1] 的和最大，为 6。

#### 34.算法

图森卡车进行的是仓到仓的运输工作，目前各个地区的仓库以及仓库间的高速公路组成了一棵树，卡车需要能够从任意一个仓库运输到另一个仓库。 

 卡车通过相邻仓库之间的高速公路需要用 1 个单位的油，求油箱需要设置多大才能满足运输要求（运输途中不能加油）

#### 35.算法

给定 n 个[算法]()训练任务，每个任务都要独占机器 1 小时。原来第 i 个任务应在第 i 小时开始做。由于突发情况停电了 k 小时，所有任务都要推迟，即时间区间从原来的 [1, n] 改为 [1+k, n+k] 小时。 

 但是第 i 个任务每推迟一小时就会损失 cost[i]。现在要对这 n 个任务重新调度顺序，要求不能原来开始时间更早，求最小的损失。

#### 36.判断是否完美二叉树LeetCode958 

#### 37.go实现一个哈希表？

#### 38.红黑树

#### 39.判断有向图是否有环？

#### 40.如何判断技能是否在CD？(例如用了技能A,CD为五秒,再次使用怎么判断是否能用)

#### 41.**有10个元素存到长度为12的数组中，有两个元素重复，找出这两个元素**

比如a+b通过把元素累加在进行减法运算可以得到a+b
通过累乘再进行除法运算可以得到a*b的值
考虑到假如元素溢出，那么可已通过平方累加得到a^2+b^2的值，根据关系式可以求得a，b的值

#### 42.股票问题，剑指63

#### 43.顺时针打印矩阵

#### 44.数组中找出和为k的两个元素返回下标

#### 45.leetcode 560

#### 46.无头节点的链表元素删除

#### 47.10进制转7进制

#### 48.判断数独的有效性

#### 49.手撕AVL树

#### 50.手撕哈希表

#### 51.连续子序列的最大和并返回所有序列

#### 52.非递归形式的前序遍历

#### 53.k个有序链表合并

#### 54.最大连续子序列和

#### 55.string类型加法实现

#### 56.爬楼梯，不允许到达7的倍数层，再优化为线性（不能用动态规划）

### 5.MySQL

#### 1.为什么采用自增索引，而不是系统随机生成的

1、如果表使用自增主键，那么每次插入新的记录，记录就会**顺序添加**到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页

2、如果使用非自增主键，由于每次插入主键的值近似于随机，因此**每次新纪录都要被插到现有索引页得中间某个位置**，此时MySQL不得不为了将新记录插到合适位置而**移动数据**，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，**同时频繁的移动、分页操作造成了大量的碎片**，得到了不够紧凑的索引结构，后续不得不通过**OPTIMIZE TABLE**来重建表并优化填充页面。



1. InnoDB中表中的数据是**直接存储在主键聚簇索引的叶子节点中**的，每插入一条记录，其实都是增加一个叶子节点，如果主键是顺序的，只需要把新增的一条记录存储在上一条记录的后面，当页达到最大填充因子的时候，下一跳记录就会写入新的页中，这种情况下，**主键页就会近似于被顺序的记录填满**。
2. 若表的主键不是顺序的id，而是无规律数据，比如字符串，InnoDB无法加单的把一行记录插入到索引的最后，而是需要找一个合适的位置（已有数据的中间位置），甚至产生大量的页分裂并且移动大量数据，在寻找合适位置进行插入时，目标页可能不在内存中，这就导致了**大量的随机IO操作**，影响插入效率。除此之外，大量的页分裂会导致大量的内存碎片。

#### 2.mysql为什么采用B+树，相比B树和平衡二叉树有什么优劣？

红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B Tree 作为索引结构，主要有以下两个原因：

**（一）更少的检索次数**

**平衡树检索数据的时间复杂度等于树高 h**，而树高大致为 O(h)=**O(logdN)**，其中 **d 为每个节点的出度**。

红黑树的出度为 2，而 **B Tree 的出度一般都非常大**。红黑树的树高 h 很明显比 B Tree 大非常多，因此检索的次数也就更多。

B+Tree 相比于 B-Tree 更适合外存索引，因为 B+Tree 内**节点去掉了 data 域**，因此**可以拥有更大的出度，检索效率会更高。**同时作为关系数据库，B+树的结点之间用链指针连接的特性**更适合范围性的查找**。

**（二）利用计算机预读特性**

为了减少磁盘 I/O，磁盘往往不是严格按需读取，而是每次都会预读。这样做的理论依据是计算机科学中著名的**局部性原理**：当一个数据被用到时，其附近的数据也通常会马上被使用。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的旋转时间，因此速度会非常快。

操作系统一般将内存和磁盘分割成固态大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。**数据库系统将索引的一个节点的大小设置为页的大小**，使得一次 I/O 就能完全载入一个节点，并且可以利用预读特性，相邻的节点也能够被预先载入。

#### 3.mysql索引和mongoDB区别

B+树和B树。B树所有**数据都存在节点上，叶子节点之间无关联**；B+树所有数据都存在叶子节点上，且**节点之间有有链指针**，叶子节点以上的节点存的是数据所在的位置（也就是指针）。

##### Mongodb和Mysql索引选型

1)首先两种数据库都选择**平衡m叉树作为底层索引结构**，因为平衡树m叉树是同种元素序列情况下的**深度最小**的m叉排序树。这可以减少m叉树元素查找的深度，从而提升平均查找效率。B树和B+树都是平衡m叉树。
2)Mongodb选择B树为索引结构，Mongodb是典型的**非关系数据库**，设计之初就不会用来做多个遍历操作，那么如果**要查询单条数据的话只要进行一次中序遍历**，查到与叶子上数据相同的节点即可。
3)Mysql是典型的关系型数据库，选择B+树的原因是**所有节点的数据都有前后关系**，因为**有链指针**，由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。因此任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当，**B+树的查询效率更加稳定**。而且把**所有同一内部节点的关键字存放在同一盘块中**，这样磁盘容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对**IO读写次数就降低**了。

#### 4.隔离级别及解决问题

##### 读未提交

##### 读已提交（丢失修改，脏读）

##### 可重复读（不可重复读）

加间隙锁解决幻读

##### 串行化

#### 5.什么情况适合建立索引？

##### 适合建索引

　　1. 频繁**作为where条件语句查询**的字段

　　2. **关联字段**需要建立索引，例如**外键字段**，student表中的classid,  classes表中的schoolid 等

　　3. **排序字段**可以建立索引

　　4. **分组字段**可以建立索引，因为分组的前提是排序

　　5. **统计字段**可以建立索引，例如count(),max()

##### 不适合建索引

　　1.**频繁更新**的字段不适合建立索引

　　2.where条件中用不到的字段不适合建立索引

　　3.**表数据可以确定比较少**的不需要建索引

　　4.数据重复且发布比较均匀的的字段不适合建索引（**唯一性太差**的字段不适合建立索引），例如性别，真假值

　　5. **参与列计算的列**不适合建索引

#### 6.如何通过索引避免出现重复ID？(建立唯一索引)

它与"普通索引"类似，不同的就是：

**索引列的值必须唯一，但允许有空值**。如果是组合索引，则列值的组合必须唯一。它有以下几种创建方式：
（1）创建索引：CREATE UNIQUE INDEX indexName ON tableName(tableColumns(length))
（2）修改表结构：ALTER tableName ADD UNIQUE [indexName] ON (tableColumns(length))
（3）创建表的时候直接指定：CREATE TABLE tableName ( [...], UNIQUE [indexName] (tableColumns(length)

#### 7.数据库中已经有重复ID数据，如何去重？(自连接)

#### 8.覆盖索引和非覆盖索引的区别

覆盖索引：SQL只需要通过索引就可以返回查询所需要的数据，而不必通过二级索引查到主键之后再去查询数据。

#### 9.mysql存储引擎的区别

#### 10.mysql聚集索引和非聚集索引，以及底层实现

MyISAM和InnoDB，分别实现了非聚簇索引和聚簇索引。

##### 非聚簇索引

非聚簇索引的**主索引和辅助索引几乎是一样**的，只是主索引不允许重复，不允许空值，他们的**叶子结点的key都存储指向键值对应的数据的物理地址**。

非聚簇索引的**数据表和索引表是分开存储的**。非聚簇索引中的数据是**根据数据的插入顺序保存**。因此非聚簇索引**更适合单个数据的查询**。插入顺序不受键值影响。

##### 聚簇索引

聚簇索引的**主索引的叶子结点存储的是键值对应的数据本身**，**辅助索引的叶子结点存储的是键值对应的数据的主键键值**。因此主键的值长度越小越好，类型越简单越好。

聚簇索引的**数据和主键索引存储在一起**。

聚簇索引的数据是**根据主键的顺序保存**。因此适合按主键索引的**区间查找，可以有更少的磁盘I/O**，加快查询速度。但是也是因为这个原因，聚簇索引的**插入顺序最好按照主键单调的顺序插入，否则会频繁的引起页分裂(BTree插入时的一个操作)，严重影响性能**。

#### 11.mysql怎么监控流量？

Openfalcon

#### 12.怎么建索引？

```sql
CREATE TABLE IF NOT EXISTS `mytable` (
   `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
   `video_id` bigint unsigned NOT NULL DEFAULT 0,
   `uid` int unsigned NOT NULL DEFAULT 0,
   `country` varchar(194)  NOT NULL ,
   `class` varchar(64)  NOT NULL ,
   `status` tinyint(4) unsigned NOT NULL DEFAULT '0',
   `video_view` bigint(20) unsigned NOT NULL DEFAULT '0',
   `created` timestamp  NOT NULL DEFAULT CURRENT_TIMESTAMP,
   PRIMARY KEY (
       `id`
   )
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
SELECT * FROM mytable WHERE created > ? AND class = ? AND country IN (?) ORDER BY created DESC LIMIT 100;
SELECT * FROM mytable WHERE class = ? AND country IN (?) ORDER BY video_view DESC LIMIT 100;
SELECT * FROM mytable WHERE created > ? AND class IN (?) LIMIT 100;
SELECT * FROM mytable WHERE created > ? AND country IN (?) LIMIT 100;
```

#### 13一个SQL语句的执行过程

##### 查询语句

- 先检查该语句是**否有权限**，如果没有权限，直接返回错误信息，如果有权限，在 MySQL8.0 版本以前，会先**查询缓存**，以这条 sql 语句为 key 在内存中查询是否有结果，如果有直接缓存，如果没有，执行下一步。
- 通过**分析器进行词法分析**，提取 sql 语句的**关键元素**，然后判断这个 sql 语句是否有语法错误，比如关键词是否正确等等，如果检查没问题就执行下一步。
- 接下来就是**优化器进行确定执行方案**，根据自己的优化算法进行选择执行效率最好的一个方案（优化器认为，有时候不一定最好）执行。

- 进行**权限校验**，如果没有权限就会返回错误信息，如果有权限就会调用数据库引擎接口，返回引擎的执行结果。

##### 更新语句

其实条语句也基本上会沿着上一个查询的流程走，只不过执行更新的时候肯定要记录日志，这就会引入日志模块了，MySQL 自带的日志模块式 **binlog（归档日志）** ，所有的存储引擎都可以使用，我们常用的 InnoDB 引擎还自带了一个日志模块 **redo log（重做日志）**，我们就以 InnoDB 模式下来探讨这个语句的执行流程。流程如下：

- 先查询到这一条数据，如果有缓存，也是会用到缓存。
- 然后拿到查询的语句，把 age 改为 19，然后调用引擎 API 接口，写入这一行数据，InnoDB 引擎把数据保存在内存中，同时**记录 redo log**，此时 redo log 进入 **prepare 状态**，然后告诉执行器，执行完成了，随时可以提交。
- 执行器收到通知后**记录 binlog**，然后调用引擎接口，**提交 redo log 为提交状态**。
- 更新完成。

#### 14.mysql的join的计算的算法？

SQL的实现join的三种算法，分别是Nested Loop Join，Hash join，Sort Merge Join。MySQL只支持**Nested Loop Join**

NLJ是通过**两层循环**，用**第一张表做Outter Loop，第二张表做Inner Loop**，**Outter Loop的每一条记录跟Inner Loop的记录作比较，符合条件的就输出**。而NLJ又有3种细分的算法：

##### *1.Simple Nested Loop Join（SNLJ）*

SNLJ就是两层循环全量扫描连接的两张表，得到符合条件的两条记录则输出，这也就是**让两张表做笛卡尔积，比较次数是R * S**，是比较暴力的算法，会比较耗时。

##### *2.Index Nested Loop Join（INLJ）*

INLJ是在SNLJ的基础上做了优化，**通过连接条件确定可用的索引**，**在Inner Loop中扫描索引而不去扫描数据本身**，从而提高Inner Loop的效率。
而INLJ也有缺点，就是**如果扫描的索引是非聚簇索引，并且需要访问非索引的数据，会产生一个回表读取数据的操作，这就多了一次随机的I/O操作**。

在MySQL5.6中，对INLJ的**回表操作进行了优化**，增加了Batched Key Access Join（**批量索引访问的表关联方式**）和Multi Range Read（mrr，**多范围读取**）特性，**在join操作中缓存所需要的数据的rowid**，再批量去获取其数据，**把I/O从多次零散的操作优化为更少次数批量的操作**，提高效率。

##### *3.Block Nested Loop Join（BNLJ）*

一般情况下，MySQL优化器**在索引可用的情况下**，会**优先选择使用INLJ算法**，但是**在无索引可用，或者判断full scan可能比使用索引更快的情况**下，还是**不会选择使用过于粗暴的SNLJ算法**。这里就出现了BNLJ算法了，BNLJ在SNLJ的基础上使用了**join buffer**，会**提前读取Inner Loop所需要的记录到buffer中**，以提高Inner Loop的效率。



#### 15.堆组织表，索引组织表，索引聚簇表

##### 堆组织表

通常我们默认建的表就是堆组织表。此类型的表中，数据会以**堆**的方式进行管理，**增加数据时候，会使用段中找到的第一个能放下此数据的自由空间**。当从表中删除数据时候，则允许以后的UPDATE和INSERT重用这部分空间，它是以一种有些**随机**的方式使用。

**全表扫描时，会按命中的顺序来获取数据，而不是按插入的顺序**。这是一个必要要了解的重要的数据库概念。一般来说，**数据库表本质上是无序的数据组合**。

```mysql
Create table test( 
  Id int, 
  Name varchar2(10) 
 );
```

##### 索引组织表(IOT)

就是**存储在一个索引结构中的表**，数据**按主键进行存储和排序**。适用的场景：

- **完全由主键组成的表**。这样的表如果采用堆组织表，则表本身完全是多余的开销，因为所有的数据全部同样也保存在索引里，此时，堆表是没用的。
- **代码查找表**。如果你**只会通过一个主键来访问一个表**，这个表就非常适合实现为IOT.
- 如果想**保证数据存储在某个位置上，或者希望数据以某种特定的顺序物理存储**，IOT就是一种合适的结构。 

**IOT提供如下的好处**：

- **提高缓冲区缓存效率**，因为给定查询在缓存中需要的块更少。
- **减少缓冲区缓存访问**，这会改善可扩缩性。
- **获取数据的工作总量更少**，因为获取数据更快。
- 每个查询完成的物理I/O更少。
- 如果**经常在一个主键或唯一键上使用between查询**，也是如此。如果数据**有序**地物理存储，就能提升这些查询的性能。

```mysql
create table indexTable(
  ID varchar2 (10), 
  NAME varchar2 (20), 
  constraint pk_id primary key (ID)
  ) organization index;
```

##### 索引聚簇表

聚簇是指：如果**一组表有一些共同的列**，则**将这样一组表存储在相同的数据库块**中；聚簇还表示**把相关的数据存储在同一个块上**。利用聚簇，**一个块可能包含多个表的数据**。概念上就是**如果两个或多个表经常做链接操作，那么可以把需要的数据预先存储在一起**。

聚簇还可以用于**单个表，可以按某个列将数据分组存储**。 

**语法**：

索引聚簇表是**基于一个索引聚簇（index cluster）创建**的。里面记录的是**各个聚簇键**。聚簇键和我们用得做多的索引键不一样，**索引键指向的是一行数据，聚簇键指向的是一个ORACLE BLOCK**。我们可以先通过以下命令创建一个索引簇。

######  什么时候不应该使用聚簇？

1. 如果**预料到聚簇中的表会大量修改**：必须知道，**索引聚簇会对DML的性能产生某种负面影响**（特别是INSERT语句）。管理聚簇中的数据需要做更多的工作。
2. 如果**需要对聚簇中的表执行全表扫描**：不只是必须对你的表中的数据执行全面扫描，还必须对（可能的）多个表中的数据进行全面扫描。由于需要扫描更多的数据， 所以全表扫描耗时更久。
3. 如果你认为需要频繁地**TRUNCATE和加载表：聚簇中的表不能截除**。这是显然的，因为聚簇在一个块上存储了多个表，必须删除聚簇表中的行。

因此，如果**数据主要用于读**（这并不表示“从来不写”；聚簇表完全可以修改），**而且要通过索引来读**（可以是聚簇键索引，也可以是聚簇表上的其他索引），另外**会频繁地把这些信息联结在一起**，此时聚簇就很适合。

#### 16.多级索引，最左前缀匹配

##### 二级索引

**叶子节点中存储主键值**，每次查找数据时，根据索引找到叶子节点中的主键值，根据主键值再到聚簇索引中得到完整的一行记录。

问题：

1.相比于叶子节点中存储行指针，二级索引存储主键值会占用更多的空间，那为什么要这样设计呢？

　　**InnoDB在移动行时，无需维护二级索引，因为叶子节点中存储的是主键值，而不是指针**。

2.那么InnoDB有了聚簇索引，为什么还要有二级索引呢？

　　聚簇索引的叶子节点存储了一行完整的数据，而**二级索引只存储了主键值，相比于聚簇索引，占用的空间要少**。当我们需要为表建立多个索引时，如果都是聚簇索引，那将占用大量内存空间，所以InnoDB中主键所建立的是聚簇索引，而**唯一索引、普通索引、前缀索引**等都是二级索引。

##### 最左前缀匹配

在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，**在检索数据时从联合索引的最左边开始匹配**。

索引的底层是一颗B+树，那么联合索引的底层也就是一颗B+树，只不过联合索引的B+树节点中存储的是键值。由于**构建一棵B+树只能根据一个值来确定索引关系**，所以**数据库依赖联合索引最左的字段来构建**。

#### 17.锁的算法（Record Lock\Gap Lock\Next-key Lock）,悲观锁和乐观锁

**InnoDB 存储引擎的锁的算法有三种：**

- Record lock：**单个行记录上**的锁。
- Gap lock：**间隙锁**，锁定一个**范围，不包括记录本身**。
- Next-key lock：record+gap 锁定一个范围，包含记录本身。

#### 18.1-3范式

1NF:字段不可分;

2NF:有主键，非主键字段依赖主键;

3NF:非主键字段不能相互依赖;

解释:

1NF:原子性 字段不可再分,否则就不是关系数据库;

2NF:唯一性 一个表只说明一个事物;

3NF:每列都与主键有直接关系，不存在传递依赖;

#### 19.Mysql查询优化

##### 1. 使用Explain进行分析

**Explain** 用来分析 **SELECT** 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。

比较重要的字段有：

- **select_type** : 查询类型，有简单查询、联合查询、子查询等
- **key** : 使用的索引
- **rows** : 扫描的行数

##### 2. 优化数据访问

###### ① 减少请求的数据量

- 只返回**必要的列**：最好**不要使用 SELECT *** 语句。
- 只返回**必要的行**：使用 **LIMIT** 语句来**限制**返回的数据。
- **缓存**重复查询的数据：使用**缓存**可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。

###### ② 减少服务器端扫描的行数

最有效的方式是**使用索引来覆盖查询**。

##### 3. 重构查询方式

###### ① 切分大查询

一个**大查询**如果**一次性执行**的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。

###### ② 分解大连接查询

将一个**大连接**查询分解成对每一个表进行**一次单表查询**，然后在应用程序中进行关联，这样做的好处有：

- 让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。
- **分解成多个单表查询**，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。
- 减少锁竞争；
- 在**应用层进行连接**，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩（阿里推荐）。
- 查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。

#### 20.事务的特性ACID

原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）

- 原子性：一个事务（transaction）中的所有操作可以被视为一个不可分割的**最小执行单元**，要么**全部完成**，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被**回滚**（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。
- 一致性：数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。在事务开始之前和事务结束以后，数据库的完整性没有被破坏。
- 隔离性：一个事务所做的修改在**最终提交**以前，对其它事务是**不可见**的。
- 一旦事务**提交**，则其所做的**修改**将会**永远保存**到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。

#### 21.Mysql怎么去查询的，什么时候走索引，什么时候不走？

哪些情况下不走索引：

- 如果MySQL估计使用**全表扫秒比使用索引快**，则不适用索引。

    例如，如果列key均匀分布在1和100之间，下面的查询使用索引就不是很好：select * from table_name where key>1 and key<90;

- 如果**条件中有or**，即使其中有条件带索引也不会使用

    例如：select * from table_name where key1='a' or key2='b';如果在key1上有索引而在key2上没有索引，则该查询也不会走索引

- 复合索引，如果索引列**不是复合索引的第一部分**，则不使用索引（即**不符合最左前缀**）

    例如，复合索引为(key1,key2),则查询select * from table_name where key2='b';将不会使用索引

- 如果**like是以 % 开始的**，则该列上的索引不会被使用。

    例如select * from table_name where key1 like '%a'；该查询即使key1上存在索引，也不会被使用。

- 如果**列为字符串，则where条件中必须将字符常量值加引号**，否则即使该列上存在索引，也不会被使用。

    例如,select * from table_name where key1=1;如果key1列保存的是字符串，即使key1上有索引，也不会被使用。

- 如果使用MEMORY/HEAP表，并且where条件中不使用“=”进行索引列，那么不会用到索引，head表只有在“=”的条件下才会使用索引

#### 22.mysql怎么存储时间？把邮戳转化为日常格式时间的函数？

##### 字符串存储日期

缺点：占用空间大；比较效率低：只能逐个字符对比，不能用日期相关的API计算

##### Datetime和Timestamp

首选TimeStamp。

- DateTime类型**没有时区信息**的（时区无关）
    DateTime 类型保存的时间都是当前会话所设置的时区对应的时间。这样就会有什么问题呢？当你的时区更换之后，比如你的**服务器更换地址或者更换客户端连接时区设置**的话，就会导致你从数据库中读出的时间错误。

- Timestamp和时区有关
    Timestamp 类型字段的值会随着服务器时区的变化而变化，自动换算成相应的时间，说简单点就是在不同时区，查询到同一个条记录此字段的值会不一样。

- DateTime 类型**消耗空间更大**
    Timestamp 只需要使用 **4 个字节**的存储空间，但是 DateTime 需要耗费 **8 个字节**的存储空间。但是，这样同样造成了一个问题，**Timestamp 表示的时间范围更小**。DateTime ：1000-01-01 00:00:00 ~ 9999-12-31 23:59:59。Timestamp：1970-01-01 00:00:01 ~ 2037-12-31 23:59:59

##### 数值型时间戳

我们也可以使用int或者bigint类型的数值也就是时间戳来表示时间

**unix_timestamp将时间转化成时间戳格式。**
**from_unixtime将时间戳转化成时间格式。**

#### 23.mysql的锁，用什么语句实现数据库锁？

##### 封锁粒度

行级锁和表级索

##### 封锁类型

###### 读写锁

- 排它锁，写锁
- 共享锁，读锁

###### 意向锁

通过引入**意向锁**，例如一个事务想对表加锁，就不需要单独检测每一行是否加锁，只需要知道是否在这个表上加了意向锁即可。因为进行行锁之前，需要先对整个表加意向锁。

##### 封锁协议

###### 三级封锁协议

**一级封锁协议**：事务 T 要**修改数据** A 时必须加 **X 锁**，直到 T **结束才释放锁**。解决**丢失修改**问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。

**二级封锁协议**：在一级的基础上，要求**读取数据** A 时必须**加 S 锁**，读取完==**马上释放 S 锁**==。可以**解决读脏数据**问题，因为如果一个事务在对数据 A 进行**修改**，根据 1 级封锁协议，会加 **X 锁**，那么就**不能再加 S 锁**了，也就是**不会读入**数据。

**三级封锁协议**：在二级的基础上，要求**读取数据 A** 时必须**加 S 锁**，直到==**事务结束**==了**才能释放 S 锁**。（注意前面是读完**立即**释放）。可以解决**不可重复读**的问题，因为**读 A** 时，其它事务**不能对 A 加 X 锁**，从而**避免了在读的期间数据发生改变**。

###### 两段锁协议

加锁和解锁分为**两个阶段**进行。可串行化调度是指，通过**并发控制**，使得**并发执行**的事务结果与**某个串行**执行的事务结果**相同**。事务遵循两段锁协议是**保证可串行化调度**的充分条件。

MySQL 的 **InnoDB 存储**引擎采用**两段锁协议**，会根据**隔离级别**在需要的时候**自动加锁**，并且所有的锁都是在**同一时刻**被释放，这被称为**隐式锁定**。

InnoDB 也可以使用特定的语句进行**显示锁定**：

```sql
SELECT ... LOCK In SHARE MODE;
SELECT ... FOR UPDATE;
```



#### 24.联合索引的使用原则

1. 需要**加索引的字段，要在 where 条件中**
2. 数据量少的字段不需要加索引
3. 如果 **where 条件中是OR关系，加索引不起作用**
4. **符合最左原则**

#### 25.Innodb的索引有哪些？

##### 1.B+树索引

适用于**全键值、键值范围和键前缀**查找，其中键前缀查找只适用于==**最左前缀**==查找。如果**不是按照索引列的顺序进行查找，则无法使用索引。**

InnoDB 的 B+Tree 索引分为**主索引和辅助索引**。主索引的**叶子节点** data 域记录着**完整**的**数据**记录，这种索引方式被称为==**聚簇索引**==。因为无法把数据行存放在两个不同的地方，所以一个表只能有**一个**聚簇索引。

**辅助索引**的**叶子节点**的 data 域记录着**主键的值**，因此在使用**辅助索引**进行查找时，需要先查找到**主键值**，然后再到主索引中进行查找。

##### 2.哈希索引

**哈希索引**能以 **O(1)** 时间进行查找，但是**失去了有序性**：

- **无法**用于**排序与分组**；
- 只支持**精确查找**，无法用于**部分查找和范围查找**。

InnoDB 存储引擎有一个特殊的功能叫“**自适应哈希索引**”，当某个索引值被使用的**非常频繁**时，会在 **B+Tree 索引之上**再创建一个**哈希索引**，这样就让 B+Tree 索引具有哈希索引的一些优点，比如**快速**的哈希查找。就是对需要查询的字段做一次哈希，然后进行查找。查找速度非常快，性能也很高。

##### 3. 全文索引

MyISAM 存储引擎支持**全文索引**，用于查找文本中的**关键词**，而不是直接比较是否相等。

查找条件使用 ==**MATCH AGAINST**==，而不是普通的 WHERE。

全文索引使用**倒排索引**实现，它记录着**关键词**到其所在**文档的映射**。

InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。

##### 4. 空间数据索引

MyISAM 存储引擎支持**空间数据索引**（**R-Tree**），可以用于**地理数据**存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。必须使用 GIS 相关的函数来维护数据。

#### 26.如果一个表查询，插入等很慢，该怎么解决？

##### 1. 针对偶尔很慢的情况

一条 SQL 大多数情况正常，偶尔才能出现很慢的情况，针对这种情况，我觉得这条SQL语句的书写本身是没什么问题的，而是其他原因导致的

###### ① 数据库在刷新脏页（flush）

当我们要往数据库插入一条数据、或者要更新一条数据的时候，我们知道数据库会在**内存**中把对应字段的数据更新了，但是更新之后，这些更新的字段并不会马上同步持久化到**磁盘**中去，而是把这些更新的记录写入到 redo log 日记中去，等到空闲的时候，在通过 redo log 里的日记把最新的数据同步到**磁盘**中去。

当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“**脏页**”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。

**刷脏页有下面 4 种场景（后两种不用太关注“性能”问题）**：

- **redolog 写满了：**redo log 里的容量是有限的，如果数据库一直很忙，更新又很频繁，这个时候 redo log 很快就会被写满了，这个时候就没办法等到空闲的时候再把数据同步到磁盘的，只能暂停其他操作，全身心来把数据同步到磁盘中去的，而这个时候，**就会导致我们平时正常的SQL语句突然执行的很慢**，所以说，数据库在在同步数据到磁盘的时候，就有可能导致我们的SQL语句执行的很慢了。
- **内存不够用了：**如果一次查询较多的数据，恰好碰到所查数据页不在内存中时，需要申请内存，而此时恰好内存不足的时候就需要淘汰一部分内存数据页，如果是干净页，就直接释放，**如果恰好是脏页就需要刷脏页**。
- **MySQL 认为系统“空闲”的时候：**这时系统没什么压力。
- **MySQL 正常关闭的时候：**这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。

###### ② 拿不到锁

这个就比较容易想到了，我们要执行的这条语句，刚好这条语句涉及到的**表**，别人在用，并且加锁了，我们拿不到锁，只能慢慢等待别人释放锁了。或者，表没有加锁，但要使用到的某个一行被加锁了，这个时候，我也没办法啊。

如果要判断是否真的在等待锁，我们可以用 **show processlist** 这个命令来查看当前的状态。

##### 2. 针对一直都很慢的情况

###### ① 没有用到索引

- SQL 就没用索引。只能走全表扫描。
- 写了索引但是没用到索引。要注意这种**字段上有索引，但由于自己的疏忽，导致系统没有使用索引**的情况了。
- **函数操作导致没有用上索引**。如果我们在查询的时候，对字段进行了函数操作，也是会导致没有用上索引的。



### 6.Redis

#### 1.redis延时推送

#### 2.实现一个本地延迟推送的数据结构（堆）

#### 3.Zset底层

#### 4.堆的性质

#### 5.cache，缓存算法

#### 6.redis的map怎么实现？让你来设计一个map，你会考虑哪些因素

#### 7.了解哈希吗？

#### 8.哈希冲突解决？

#### 9.Redis底层数据结构

#### 10.Redis持久化策略

#### 11.为什么使用单线程？

#### 12.go map 和 redis map

#### 13.缓存和数据库一致性的问题

#### 14.redis和etcd的区别

- 从数据结构方面来讲 Redis支持多种数据类型（string，set，list，hash，zset） 
- 从读写性能上来讲，Redis读写性能优异，并且提供了RDB、AOF持久化，而etcd v3的底层采用boltdb做存储，value直接持久化 
- 从使用场景上来看，etcd更适用于服务发现，配置管理，而Redis更适用于非强一致性的需求，比如说是队列，缓存，分布式Session
- 两者都是KV存储，但是etcd通过Raft算法保证了各个节点间的数据和事务的一致性，更强调各个节点间的通信；Redis则时更像是内存式的缓存，因此来说读写能力很强。 
- Redis是c开发的，etcd是go开发的，他是源于k8s的兴起作为一个服务发现。 
- etcd v3只能通过gRPC访问，而redis可以通过http访问，因此etcd的客户端开发工作量高很多。

#### 15.etcd的raft算法

#### 16.Redis缓存策略

#### 17.分布式CAP原理

#### 18.Redis持久化的区别

#### 19.redis为什么快？

#### 20.Redis的多集群方案

#### 21.Redis哨兵如何通信，哨兵如何监控数据节点，哨兵自己失效如何处理？

#### 22.缓存和缓存后面的数据库如何保证数据的一致性？

#### 23.LRU算法中，如果有数据插入进来会到队列头部，那如果有大量数据插入进来，原来的热数据是不是会被挤掉？怎么解决这个问题？

#### 24.一致性哈希

#### 25.Redis的内存淘汰策略

### 7.消息队列

#### 1.消息队列的作用和应用场景

#### 2.Kafka如何保证消息有序，丢失消息和不重复消费

#### 3.限流的算法，消息队列怎么限流，消费方如何返回给消息生产方

固定/滑动窗口，消息队列，令牌桶。

同步的话就阻塞，等待返回；异步的话，可以从另一个topic里面取？（不确定）

### 8.项目场景相关

#### 1.设计一个短链接服务怎么做

#### 2.设计一个登录系统，包括账户密码登录，验证码登录，第三方授权等等。详细说

#### 3.项目高并发场景，限流和熔断等

#### 4.设计一个秒杀系统

#### 5.讲一个最熟悉的数据结构

#### 6.10亿的URL去重怎么做？

#### 7.redis用过哪些API

#### 8.线上问题一般怎么排查，比如oom

#### 9.docker和虚拟机区别

#### 10.k8s底层原理

#### 11.微服务拆分

#### 12.负载均衡的实现

#### 13.在实现的虚拟链路中keep alive是怎么实现的？

#### 14.怎么查找程序的性能瓶颈？

#### 15.排行榜的设计

#### 16.gRPC过程

#### 17.pprof使用

#### 18.性能调优怎么做

#### 19.常见的负载均衡算法？

#### 20.etcd和zookeeper区别

#### 21.mysql如何进行后期优化的？

#### 22.2PC的过程，优缺点。3PC

#### 23.Unicode编码，GBK，UTF-8，Latin

#### 24.CAS

#### 25.登陆页面功能的实现

#### 26.分布式系统的资源调度算法

#### 27.怎么算QPS？

#### 28.布隆过滤器

#### 29.微服务治理

#### 30.如何实现服务的平滑升级？

#### 31.分布式算法

#### 32.rpc框架序列化解决了什么问题？

#### 33.grpc框架

#### 34.了解什么中间件吗？

#### 35.分布式锁改进和优化

#### 36.怎么处理锁分段？

#### 37.gRPC和jsonrpc的优劣

#### 38.路由网关和注册中心的实现

#### 39.如何实现链路追踪？

#### 40.RPC概念



#### 10.一个先递增后递减的数组找出独特元素的个数

#### 5.怎么在10万个数中找最大的10个数

#### 5.旋转数组的最小数字

#### 1.两个数组找出两个数差值绝对值最小

#### 1.给定一个int数组A，给定一个数x，求所有求和能得到x的数字组合，组合中的元素来自A

#### 6.常用排序算法的时间空间复杂度

#### 7.二叉树的最近公共祖先

#### 2.青蛙跳台阶问题

#### 19.数组找top k,时间复杂度分析（快排、堆排），能不能优化到O(K)，可以用桶排序

#### 20.快排的时间复杂度是O(nlogn)，你有哪些优化时间复杂度的方法吗？比如空间换时间

#### 1.红黑树和AVL树区别

#### 2.两个区间数组，求彼此区间的交集

#### 3.KMP

#### 4.手写单例模式

#### 6.归并排序

#### 1.两个有序数组合成一个有序数组，不允许有重复数据

#### 16.dfs和bfs的区别

#### 19.单向链表的复制

单项链表还有个random域指针这个有可能指向了前后的结点。
完成这个[链表](https://www.nowcoder.com/jump/super-jump/word?word=链表)的深复制。包括random域也要复制新的链新的。

#### 7.36匹马，6个跑道，最少跑多少趟就可以筛选出前三匹最快的马？

六路归并排序

#### 8.顺时针打印二维矩阵

#### 8.两个栈实现一个队列

#### 7.海量数字，范围都是1-10000，怎么排序？

计数排序

#### 8.十进制IP地址转为32位整数

#### 9.实现一个位图，包含 `constructor(int size)`、`check(int val)`、`put(int val)` 三个方法 

```go
// 位图
package main

import (
    "fmt"
)

type BitMap struct {
    bits []byte
}

func NewBitMap(capacity int) BitMap {
    return BitMap{make([]byte, (capacity+7)/8)}
}

func (bitmap *BitMap) Set(num int) {
    if (num > 8*len(bitmap.bits)) {
        return
    }
    pos := num / 8
    offset := uint(num % 8)
    bitmap.bits[pos] |= (0x80 >> offset)
}

func (bitmap *BitMap) Check(num int) bool {
    if (num > 8*len(bitmap.bits)) {
        return false
    }
    pos := num / 8
    offset := uint(num % 8)
    return bitmap.bits[pos] & (0x80 >> offset) > 0
}

func main() {
    bitmap := NewBitMap(15)
    bitmap.Set(2)
    bitmap.Set(15)
    bitmap.Set(30)
    fmt.Println(bitmap.Check(2))
    fmt.Println(bitmap.Check(3))
    fmt.Println(bitmap.Check(15))
    fmt.Println(bitmap.Check(30))
}
```















### Golang

#### 1.len(), cap()

#### 2.读程序

```go
const (
    i=7
    j
    k
)
// i j k分别等于多少
```

#### 3.defer，panic

```go
defer（"1"）
defer（"2"）
//请问以上输出顺序

defer（"1"）
defer（"2"）
panic（"3"）
//请问输出结果
```

#### 4.panic,recover 怎么用？

#### 5.如果一个协程Panic了，整个程序会怎么样？

#### 6.Channel实现原理

#### 7.怎么控制多个协程：定时开始，定时退出，条件开始，条件退出。（现场写）

#### 8.磁盘IO的时候怎么调度？

#### 9.网络IO的时候会出现什么情况？

#### 10.任务队列怎么实现

#### 11.怎么控制并发量？

#### 12.怎么阻塞一个协程？

#### 13.select怎么用？

#### 14.什么时候会出发GC？

#### 15.GC怎么调优？



#### 1.用过哪些消息队列？你知道的消息队列？

#### 2.常用的git操作

#### 3.merge和rebase的区别

#### 4.说一下k8s有哪些模块？

#### 5.k8s模块之间怎么通信？

#### 6.怎么让你的服务跑在集群上？用过多集群管理吗？

#### 7.微服务之间怎么通信？

#### 8.RPC

#### 9.集群服务怎么做负载均衡？



#### 1.Linux grep的用法

#### 2.Linux对一个文件中内容相同的行去重

#### 3.Go中两个map对象如何比较

#### 4.mysql查询速度慢如何优化，如何添加索引(覆盖索引/前缀匹配)

#### 5.全排列（去重）



#### 1.自己实现LRU算法，用在生产环境有什么问题？

#### 2.如果十万个线程同时put，会出现什么问题？

#### 3.程序从加载到运行的过程？

#### 4.分布式锁

#### 5.zookeeper，mysql，redis,etcd怎么实现分布式锁，各有什么优缺点？生产中一般用哪个？

#### 6.zookeeper原理，怎么保持高可用？

#### 7.tcp调优相关参数



#### 1.golang多态，父类方法重写

#### 2.mysql索引重建问题

#### 3.go怎么操作内核线程？

#### 4.大表通过主键ID删除数据会不会慢？为什么？

#### 5.怎么判断一个数是否是2的n次幂？



#### 1.delete和truncate

#### 2.断点调试的原理

#### 3.ctrl+c会发生什么？原理？

#### 4.线程的状态，sleep前后会发生什么？

#### 5.路由器IP包进路由器到出路由器哪些改变了？数据链路层呢？

#### 5.https证书校验

#### 6.NAT

#### 7.给一长串带‘../’ ‘./’ linux文件路径 输出真实路径

#### 8.traceroute原理

#### 9.协程 栈内存少，不是很容易爆栈吗？

#### 10.写一个会爆栈的代码？



#### 1.TCP如何实现纠错，防止丢失数据和重复？

#### 2.https加密流程

#### 3.数据库出现读性能问题，如何解决？

#### 4.数据库索引类型？

主键索引，哈希表索引等

#### 5.Redis读性能问题怎么解决？

#### 6.有哪些线性数据结构？

#### 7.算法：有序数组去重

#### 8.Go具体并发优秀在哪？实际测试，benchmark等

#### 9.map除了使用哈希表还用了什么？

比如B+树

#### 10.内存中的数据结构一般用什么？

红黑树。优点在于旋转开销比AVL树开销要低



#### 1.Go中struct组合和Java继承的区别

#### 2.channel有缓冲无缓冲区别

#### 3.进程间通信方式

#### 4.CPU调度算法

#### 5.页面置换算法

#### 6.3个盒子，其中一个有礼物，你先选择一个盒子，然后给你打开一个没礼物的盒子，你可以坚持自己第一次选择或者选择另外一个剩下的盒子，问是否交换以及交不交换胜率是多少。

#### 7.非递归实现层序遍历



#### 1.slice分配在堆上还是栈上？

#### 2.goroutine切换的时候上下文环境放在哪里？

#### 3.讲一下reflect

#### 4.举个乐观锁的例子

#### 5.网络中有很多sync_recv是发生了什么？

#### 6.无序数组，找两个和为k的数，怎么一次遍历完成？



#### 1.goroutine的调度出现在什么情况下？调度时发生了什么？

#### 2.interface，channel底层实现

#### 3.大量请求如何处理？

我说消息队列，线程池，异步io，引导我说多路复用

#### 4.单例模式



#### 1.Redis中如何使用epoll模型的？如果存在延时任务如何做？

#### 2.Redis主从复制

#### 3.mysql的主从复置



#### 1.使用context遇到的问题

#### 2.redis处理大文件阻塞怎么处理？

#### 3.手写队列

#### 4.手写快排

#### 5.mysql优化



#### 1.socket编程

#### 2.浏览器打开网页的流程，流程中每个协议都是运行在哪一层的？

#### 3.TLS连接过程

#### 4.Go web项目如何优雅退出

#### 5.Docker相关

#### 6.快排，非递归



#### 1. 数组中其他数出现两次有一个数出现一次找出这个数

#### 2.数组中其他数出现两次，有两个数出现一次找出这两个数

#### 3.链表A->B->C->D->E 变成B->A->D->C->E

#### 4.单调栈问题 数组中找出右边第一个比这个数大的数

比如数组合[2,10,5,8,1,2,13,12,11]

输出： [10,13,13,13,13,13,-1,-1,-1]

#### 5.tcp断开连接时保持2mls的弊端

#### 6.对称加密和非对称加密，为啥客户端不直接用服务器端发送过来的公钥加密信息进行传递？

#### 7.数字在排序数组中出现的次数

#### 8.给定数组，每个元素代表一个木头的长度，木头可以任意截断，从这堆木头中截出至少k个相同长度为m的木块，已知k，求max(m)。

#### 9.数据结构设计：时间复杂度O(1)的gemin（）最小栈

#### 10.[8,1, 9, 10, 3, 5] 每次获取一个值，不能获取相邻的，求最大值

比如第一次取出了8，第二次不能取1

#### 11.最左前缀原则

#### 12.redis缓存穿透和缓存击穿

#### 13.堆和栈的区别

#### 14.64匹马 八个赛道 求定位出前四名要进行几次比赛

归并排序？



#### 1.redlock

#### 2.设计一个短网址系统

#### 3.给定一个链表，以及m和n，翻转m和n之间的节点，m和n从0开始， m < n, m和n都可能比链表长度大

#### 4.linux下怎么实现一个单例进程

#### 5.tcp三次握手第三个包丢了会怎么样

#### 6.分布式事务

#### 7.设计一个im系统，怎么保证消息不丢失

#### 8.二维数组中的查找

#### 9.一个长度为N的数组，元素值在[1,N]之间，找出重复元素，要求时间O(n),空间O(1)



#### 1.消息队列，发布订阅机制

#### 2.sql和nosql数据库的区别

#### 3.什么情况下b树比b+树好？

#### 4.为什么要有共享内存？共享内存在操作系统的那个区域？

#### 5.怎么查看端口是否被占用，怎么杀死进程，有哪些参数？

#### 6.什么是[排序](https://www.nowcoder.com/jump/super-jump/word?word=排序)的稳定性，现实中有什么需要用到[排序](https://www.nowcoder.com/jump/super-jump/word?word=排序)的稳定性？



#### 1.异步IO

#### 2.B+树node大小多少？为什么？

#### 3.hashmap数据太多 rehash时间长 怎么解决

#### 4.rehash时候可以get put吗？

#### 5.http可以基于udp实现吗？

#### 6.进程间通信哪个效率最高？

#### 7.进程有自己独立的内存 那共享内存是怎么实现的？

#### 8.十亿数据找第十万个 quick select复杂度是O多少N？有没有更优算法？用heap nlogk？



#### 1.哪些操作会引发阻塞？

#### 2.虚拟分页，逻辑地址，分页的好处

#### 3.http2.0特性，二进制分帧的作用

#### 4.http有什么协议，多个请求下会建立多少个tcp

#### 5.Go的多线程Panic recover

#### 6.使用interface的好处



#### 1.sql如何优化

索引，返回需要的字段，避免全表扫描（不进行null判断，少进行大于小于like操作，不适用or连接，少用in）

#### 2.怎么理解前端后端

#### 3.TCP滑动窗口的实现

#### 4.TCP如何保证数据有序性？接收方收到失序报文如何确定？

#### 5.TCP数据很小如果只有一个字节会发生什么？

粘包

#### 6.TCP如何从一对一变一对多？

#### 7.数据库有多少种索引？主键和普通区别

主键，唯一，普通，全表

唯一性、全表只有一个主键索引、主键不为空，主键可作外键

#### 8.IO多路复用，同步阻塞，非同步阻塞

#### 9.深拷贝和浅拷贝

#### 10.Hashmap原理

数组链表，红黑树

#### 11.线程池创建的4种方式



#### 1.对象是如何分配到内存的？

#### 2.GO 逃逸分析

#### 3.给定一个数组，删除x时，会同时删掉所有的x-1和x+1，此时会得到x分，求能获得的最大分数

#### 4.给定数组求最大值

#### 5.零钱兑换(力扣)

#### 6.Go 管理依赖 gomod命令，gomod最后的版本号如果没有tag，是怎么生成的

#### 7.三范式，反三范式？什么时候反三范式？反三范式有什么坏处？

#### 8.联合索引，给定一些情况问是否会用到索引

#### 9.有一千万的请求，只有一千个缓存（基本都能命中），如何处理？优化思路

#### 10.每天几亿的送审量，如何保证送审安全，以及如何提升派单效率？

#### 11.DBProxy，为什么要用？他的好处是什么？是怎么提升管理？他还有什么好处？

#### 12.结果推送怎么做？MQ？



#### 1.复合索引，给SQL判断索引顺序

#### 2.复合索引的存储数据结构

#### 3.火车买票，多区间，设计表

#### 4.抖音，关注，粉丝，设计表

#### 5.算法：接雨水

#### 6.go协程交叉顺序打印数组

#### 7.手写SQL找某个列的最大的记录

#### 8.B+树和二叉树有什么区别？

#### 9.单例模式，场景，手写双重锁的

#### 10.合并k个有序数组

分治



#### 1.Go内存分配，和tcmalloc的区别

#### 2.bloom filter的原理，应用场景

#### 3.一致性哈希和普通哈希区别

#### 4.虚拟内存会不会对GC造成影响？

#### 5.OSI网络七层模型，各层作用

#### 6.TCP能建立多少连接？

#### 7.HTTPS什么情况是不可靠的？中间人攻击？

#### 8.数据库中死锁的情况

#### 9.排序字符串去重



#### 1.go http包

#### 2.Innodb中index的数据结构

#### 3.如何实现的压测？指标有哪些？有没有了解过其他开源的压测工具

#### 4.为什么要做分离存储？

#### 5.什么是DIO？

#### 6.read/write和mmap的区别？

#### 7.断电如何处理？

#### 8.内存不够或者数据量不固定怎么办？

#### 9.终端和终端启动的进程的联系

#### 10.Go如何检测死锁？

#### 11.如何实现只开100个协程？

#### 12.Docker如何管理CPU和内存资源

#### 13.kill -9无法杀死进程有哪些原因？

#### 14.OSS如何保证稳定性？

#### 15.Linux下两个路径如何判断等同？（简化路径）



#### 1.进程的几个状态的切换

#### 2.如何使用udp实现可靠传输

#### 3.有一个二维数组，行遍历和列遍历哪个快？

#### 4.扫描二维码的原理

#### 5.DNS怎么查？

#### 6.拿到IP之后怎么拿到端口？

#### 7.请求报文和回复报文格式

#### 8.服务器收到请求怎么处理？来了多个请求怎么处理？

#### 9.公网IP和内网IP怎么转换？

#### 10.concurrent hashmap的锁机制

#### 11.RPC和Restful的区别

#### 12.二叉树是否存在一条路径和等于给定值



#### 1.服务端大文件，http多线程下载

#### 2.join和left join区别

#### 3.timewait()和stopwait()

#### 4.10亿数据内存够用的情况下，选取前100

#### 5.40亿数据内存不够的情况下找出中位数



#### 1.get能把参数放在body吗？post能把参数放在URL吗？

#### 2.给SQL语句分析使用什么索引，以及索引是否能命中

#### 3.Redis持久化方式RDB和AOF，指令

#### 4.查找有序数组中一个目标值出现的第一次位置，没有找到返回-1

直接遍历，哈希表，优化用二分



#### 1.括号匹配算法

#### 2.统计一个日志文件（里面存放的是id,每访问一次会有一行id） 前10个出现的id

#### 3.最长不重复子串

#### 4.机器人走路算法

#### 5.http的无状态是什么意思？

#### 6.为什么TCP比UDP慢？



#### 1.完全二叉树和搜索二叉树

#### 2.从应用层到网络层各层的header都有什么不同的功能？

#### 3.用中序遍历和广度优先法判断是不是搜索二叉树和完全二叉树

#### 4.Redis删除key的机制，为什么要删除？

#### 5.回调函数的作用

#### 6.给定一个数组和一个数s,找到最短的字数组加起来的和超过s



#### 1.链表存储的大数加减法

#### 2.字符串存储的带优先级算术表达式计算

#### 3.五种io模型



#### 1.冒泡算法

#### 2.go的开源框架的源码理解

#### 3.取链表的中间节点

#### 4.给定N个并发量，并发处理数组



#### 1.包管理相关

#### 2.go值传递

#### 3.怎么做一个URL短网址的项目？

#### 4.Go除了goroutine还有什么处理并发的办法？

#### 5.二叉树后序遍历非递归

#### 6.大数据的排序，去重



#### 1.Go测试，性能调优

#### 2.for range陷阱

#### 3.left join和inner join的区别

#### 4.百万级Mysql怎么处理？

1.主备 2.读写分离 3.集群 4.负载均衡 5.查询缓存 6.raid

#### 5.用Go实现一个栈

